{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eDyb4ods321"
   },
   "source": [
    "# RecSys for News"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdwnFl4Ys326"
   },
   "source": [
    "The MIND dataset contains 15M impressions generated by 1M users over 160k news articles.\n",
    "\n",
    "In order to build a Recommender System, we would be first cleaning and pre-processing the data, then developing simple features to finally train and evaluate (DLRM)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-0SKaE9Ps327"
   },
   "source": [
    "## Import libraries and create directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AOq1ey2Fs328",
    "outputId": "ecf43fd6-aef6-4ad6-fef0-c95524360dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/merlin/lib/python3.8/site-packages (4.60.0)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "unzip is already the newest version (6.0-25ubuntu1).\n",
      "wget is already the newest version (1.20.3-1ubuntu1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 2 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Install packages required for this notebook\n",
    "!pip install tqdm\n",
    "!apt install wget unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUGTb47Ps32-"
   },
   "outputs": [],
   "source": [
    "import time, glob, shutil, sys, os, pickle, json\n",
    "from tqdm import tqdm\n",
    "import boto3\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "import cupy as cp          \n",
    "import cudf                \n",
    "import rmm                 \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nvtabular.ops import Operator\n",
    "import nvtabular as nvt\n",
    "from nvtabular.utils import device_mem_size\n",
    "\n",
    "import dask\n",
    "import dask_cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "from dask.distributed import wait\n",
    "from dask.utils import parse_bytes\n",
    "from dask.delayed import delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I35ZMI9As32_",
    "outputId": "55cd4041-a6c5-4a93-9070-4288cd9d3d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directories\n",
      "Downloaded MINDlarge_train/behaviors.tsv to ./basedir/dataset/train/behaviors.tsv\n",
      "Downloaded MINDlarge_train/news.tsv to ./basedir/dataset/train/news.tsv\n",
      "Downloaded MINDlarge_train/entity_embedding.vec to ./basedir/dataset/train/entity_embedding.vec\n",
      "Downloaded MINDlarge_train/relation_embedding.vec to ./basedir/dataset/train/relation_embedding.vec\n",
      "Downloaded MINDlarge_dev/behaviors.tsv to ./basedir/dataset/valid/behaviors.tsv\n",
      "Downloaded MINDlarge_dev/news.tsv to ./basedir/dataset/valid/news.tsv\n",
      "Downloaded MINDlarge_dev/entity_embedding.vec to ./basedir/dataset/valid/entity_embedding.vec\n",
      "Downloaded MINDlarge_dev/relation_embedding.vec to ./basedir/dataset/valid/relation_embedding.vec\n"
     ]
    }
   ],
   "source": [
    "# Initialize the S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# S3 bucket name and folder prefix\n",
    "bucket_name = 'rjgyrocs5w7'\n",
    "train_prefix = 'MINDlarge_train/'\n",
    "valid_prefix = 'MINDlarge_dev/'\n",
    "file_names = ['behaviors.tsv', 'news.tsv', 'entity_embedding.vec', 'relation_embedding.vec']\n",
    "\n",
    "# Define root directory where all artifacts would be saved\n",
    "BASE_DIR = os.environ.get(\"BASE_DIR\", \"./basedir\")\n",
    "\n",
    "# Define worker/output directories\n",
    "dask_workdir = os.path.join(BASE_DIR, \"workdir\")\n",
    "\n",
    "# Directory to store the raw downloaded dataset\n",
    "data_input_path = os.path.join(BASE_DIR, \"dataset\")\n",
    "data_path_train = os.path.join(data_input_path, \"train\")\n",
    "data_path_valid = os.path.join(data_input_path, \"valid\")\n",
    "\n",
    "# Directory to store pre-processed dataset\n",
    "data_output_path = os.path.join(BASE_DIR, \"processed_nvt\")\n",
    "output_train_path = os.path.join(data_output_path, \"train\")\n",
    "output_valid_path = os.path.join(data_output_path, \"valid\")\n",
    "\n",
    "# Directory to model configuration and\n",
    "config_output_path = os.path.join(BASE_DIR, \"configs\")\n",
    "weights_path = os.path.join(BASE_DIR, \"weights\")\n",
    "\n",
    "def create_clean_directory(path):\n",
    "    if os.path.isdir(path):\n",
    "        shutil.rmtree(path)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "# Creating and cleaning our worker/output directories\n",
    "try:\n",
    "    os.makedirs(BASE_DIR, exist_ok=True)\n",
    "\n",
    "    create_clean_directory(dask_workdir)\n",
    "    create_clean_directory(data_input_path)\n",
    "    create_clean_directory(data_path_train)\n",
    "    create_clean_directory(data_path_valid)\n",
    "    create_clean_directory(data_output_path)\n",
    "    create_clean_directory(output_train_path)\n",
    "    create_clean_directory(output_valid_path)\n",
    "    create_clean_directory(config_output_path)\n",
    "    create_clean_directory(weights_path)\n",
    "\n",
    "except OSError as e:\n",
    "    print(f\"Creation of the directories failed: {e}\")\n",
    "else:\n",
    "    print(\"Successfully created the directories\")\n",
    "\n",
    "# Function to download a file from S3 to the specified local path\n",
    "def download_file_from_s3(bucket, s3_key, local_path):\n",
    "    \"\"\"Download a file from S3 to the specified local path.\"\"\"\n",
    "    try:\n",
    "        s3_client.download_file(bucket, s3_key, local_path)\n",
    "        print(f\"Downloaded {s3_key} to {local_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to download {s3_key}: {e}\")\n",
    "\n",
    "# Download files for the training set\n",
    "for file_name in file_names:\n",
    "    train_s3_key = train_prefix + file_name\n",
    "    train_local_path = os.path.join(data_path_train, file_name)\n",
    "    download_file_from_s3(bucket_name, train_s3_key, train_local_path)\n",
    "\n",
    "# Download files for the validation set\n",
    "for file_name in file_names:\n",
    "    valid_s3_key = valid_prefix + file_name\n",
    "    valid_local_path = os.path.join(data_path_valid, file_name)\n",
    "    download_file_from_s3(bucket_name, valid_s3_key, valid_local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWCM8koHs33A"
   },
   "source": [
    "## Setup dask for distributed processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov 14 01:57:13 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.90.12              Driver Version: 550.90.12      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:08:00.0 Off |                  Off |\n",
      "| N/A   27C    P0             42W /  400W |       4MiB /  40960MiB |      0%      Default |\n",
      "|                                         |                        |             Disabled |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Check the GPUs that are available to this notebook\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sqi9Aaf3s33A"
   },
   "source": [
    "### Initialize Dask GPU Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:39867</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>1</li>\n",
       "  <li><b>Memory: </b>232.21 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:39867' processes=1 threads=1, memory=232.21 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "NUM_GPUS = [0] # add GPU IDs available on the server\n",
    "\n",
    "dashboard_port = \"8787\"\n",
    "\n",
    "protocol = \"tcp\"             # \"tcp\" or \"ucx\"\n",
    "visible_devices = \",\".join([str(n) for n in NUM_GPUS])  \n",
    "device_spill_frac = 0.9      \n",
    "\n",
    "# Get device memory capacity\n",
    "capacity = device_mem_size(kind=\"total\")\n",
    "\n",
    "cluster = None              \n",
    "if cluster is None:\n",
    "    cluster = LocalCUDACluster(\n",
    "        protocol = protocol,\n",
    "        n_workers=len(visible_devices.split(\",\")),\n",
    "        CUDA_VISIBLE_DEVICES = visible_devices,\n",
    "        device_memory_limit = capacity * device_spill_frac,\n",
    "        local_directory=dask_workdir,\n",
    "        dashboard_address=\":\" + dashboard_port,\n",
    "    )\n",
    "\n",
    "# Create the distributed client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4MnR_WYgs33B",
    "outputId": "e912a37b-c202-42e5-f4b3-2af5964c7cf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcp://127.0.0.1:36983': None}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize RMM pool on ALL workers\n",
    "def _rmm_pool():\n",
    "    rmm.reinitialize(\n",
    "        pool_allocator=True,\n",
    "        initial_pool_size=None,\n",
    "    )\n",
    "\n",
    "client.run(_rmm_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6BwJfiXs33B"
   },
   "source": [
    "## Explore MIND dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihPFAuHKs33B"
   },
   "source": [
    "\n",
    "\n",
    "### Dataset format\n",
    "\n",
    "Each set of this data (train/valid/test) contains the following 4 files:\n",
    "\n",
    "1. behaviors.tsv - The click history and impression logs of users\n",
    "2. news.tsv - Details of news articles mapped with the news ID\n",
    "3. entity_embedding.vec - The embeddings of entities in news extracted from knowledge graph\n",
    "4. relation_embedding.vec - The embeddings of relations between entities extracted from knowledge graph\n",
    "\n",
    "Let's take a look at both these TSV files and understand how we can utilise them for our Recommendation System. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JazC50S2s33C"
   },
   "source": [
    "### Behaviors data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K98uUz8ss33C",
    "outputId": "a1146132-61bc-4a18-9be9-cf81d947a1d0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>U87243</td>\n",
       "      <td>11/10/2019 11:30:54 AM</td>\n",
       "      <td>N8668 N39081 N65259 N79529 N73408 N43615 N2937...</td>\n",
       "      <td>N78206-0 N26368-0 N7578-0 N58592-0 N19858-0 N5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>U598644</td>\n",
       "      <td>11/12/2019 1:45:29 PM</td>\n",
       "      <td>N56056 N8726 N70353 N67998 N83823 N111108 N107...</td>\n",
       "      <td>N47996-0 N82719-0 N117066-0 N8491-0 N123784-0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>U532401</td>\n",
       "      <td>11/13/2019 11:23:03 AM</td>\n",
       "      <td>N128643 N87446 N122948 N9375 N82348 N129412 N5...</td>\n",
       "      <td>N103852-0 N53474-0 N127836-0 N47925-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>U593596</td>\n",
       "      <td>11/12/2019 12:24:09 PM</td>\n",
       "      <td>N31043 N39592 N4104 N8223 N114581 N92747 N1207...</td>\n",
       "      <td>N38902-0 N76434-0 N71593-0 N100073-0 N108736-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>U239687</td>\n",
       "      <td>11/14/2019 8:03:01 PM</td>\n",
       "      <td>N65250 N122359 N71723 N53796 N41663 N41484 N11...</td>\n",
       "      <td>N76209-0 N48841-0 N67937-0 N62235-0 N6307-0 N3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0        1                       2  \\\n",
       "0  1   U87243  11/10/2019 11:30:54 AM   \n",
       "1  2  U598644   11/12/2019 1:45:29 PM   \n",
       "2  3  U532401  11/13/2019 11:23:03 AM   \n",
       "3  4  U593596  11/12/2019 12:24:09 PM   \n",
       "4  5  U239687   11/14/2019 8:03:01 PM   \n",
       "\n",
       "                                                   3  \\\n",
       "0  N8668 N39081 N65259 N79529 N73408 N43615 N2937...   \n",
       "1  N56056 N8726 N70353 N67998 N83823 N111108 N107...   \n",
       "2  N128643 N87446 N122948 N9375 N82348 N129412 N5...   \n",
       "3  N31043 N39592 N4104 N8223 N114581 N92747 N1207...   \n",
       "4  N65250 N122359 N71723 N53796 N41663 N41484 N11...   \n",
       "\n",
       "                                                   4  \n",
       "0  N78206-0 N26368-0 N7578-0 N58592-0 N19858-0 N5...  \n",
       "1  N47996-0 N82719-0 N117066-0 N8491-0 N123784-0 ...  \n",
       "2              N103852-0 N53474-0 N127836-0 N47925-1  \n",
       "3  N38902-0 N76434-0 N71593-0 N100073-0 N108736-0...  \n",
       "4  N76209-0 N48841-0 N67937-0 N62235-0 N6307-0 N3...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviors_train = cudf.read_csv(os.path.join(data_path_train , 'behaviors.tsv'),\n",
    "                                header=None,\n",
    "                                sep='\\t',)\n",
    "behaviors_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7KRIRMWcs33C"
   },
   "outputs": [],
   "source": [
    "behaviors_columns = ['impression_id', 'uid', 'time', 'history', 'impressions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3JrQlchs33C",
    "outputId": "9381d494-ec52-48d4-80ef-a3236ec56dbc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_id</th>\n",
       "      <th>uid</th>\n",
       "      <th>time</th>\n",
       "      <th>history</th>\n",
       "      <th>impressions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>U87243</td>\n",
       "      <td>11/10/2019 11:30:54 AM</td>\n",
       "      <td>N8668 N39081 N65259 N79529 N73408 N43615 N2937...</td>\n",
       "      <td>N78206-0 N26368-0 N7578-0 N58592-0 N19858-0 N5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>U598644</td>\n",
       "      <td>11/12/2019 1:45:29 PM</td>\n",
       "      <td>N56056 N8726 N70353 N67998 N83823 N111108 N107...</td>\n",
       "      <td>N47996-0 N82719-0 N117066-0 N8491-0 N123784-0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>U532401</td>\n",
       "      <td>11/13/2019 11:23:03 AM</td>\n",
       "      <td>N128643 N87446 N122948 N9375 N82348 N129412 N5...</td>\n",
       "      <td>N103852-0 N53474-0 N127836-0 N47925-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>U593596</td>\n",
       "      <td>11/12/2019 12:24:09 PM</td>\n",
       "      <td>N31043 N39592 N4104 N8223 N114581 N92747 N1207...</td>\n",
       "      <td>N38902-0 N76434-0 N71593-0 N100073-0 N108736-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>U239687</td>\n",
       "      <td>11/14/2019 8:03:01 PM</td>\n",
       "      <td>N65250 N122359 N71723 N53796 N41663 N41484 N11...</td>\n",
       "      <td>N76209-0 N48841-0 N67937-0 N62235-0 N6307-0 N3...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impression_id      uid                    time  \\\n",
       "0              1   U87243  11/10/2019 11:30:54 AM   \n",
       "1              2  U598644   11/12/2019 1:45:29 PM   \n",
       "2              3  U532401  11/13/2019 11:23:03 AM   \n",
       "3              4  U593596  11/12/2019 12:24:09 PM   \n",
       "4              5  U239687   11/14/2019 8:03:01 PM   \n",
       "\n",
       "                                             history  \\\n",
       "0  N8668 N39081 N65259 N79529 N73408 N43615 N2937...   \n",
       "1  N56056 N8726 N70353 N67998 N83823 N111108 N107...   \n",
       "2  N128643 N87446 N122948 N9375 N82348 N129412 N5...   \n",
       "3  N31043 N39592 N4104 N8223 N114581 N92747 N1207...   \n",
       "4  N65250 N122359 N71723 N53796 N41663 N41484 N11...   \n",
       "\n",
       "                                         impressions  \n",
       "0  N78206-0 N26368-0 N7578-0 N58592-0 N19858-0 N5...  \n",
       "1  N47996-0 N82719-0 N117066-0 N8491-0 N123784-0 ...  \n",
       "2              N103852-0 N53474-0 N127836-0 N47925-1  \n",
       "3  N38902-0 N76434-0 N71593-0 N100073-0 N108736-0...  \n",
       "4  N76209-0 N48841-0 N67937-0 N62235-0 N6307-0 N3...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviors_train = cudf.read_csv(os.path.join(data_path_train , 'behaviors.tsv'),\n",
    "                          header=None,\n",
    "                          names=behaviors_columns,\n",
    "                    sep='\\t',)\n",
    "behaviors_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7J-3yI-Zs33C",
    "outputId": "f137d103-1073-44ef-f123-c401726149e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>impression_id</th>\n",
       "      <th>uid</th>\n",
       "      <th>time</th>\n",
       "      <th>history</th>\n",
       "      <th>impressions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>U134050</td>\n",
       "      <td>11/15/2019 8:55:22 AM</td>\n",
       "      <td>N12246 N128820 N119226 N4065 N67770 N33446 N10...</td>\n",
       "      <td>N91737-0 N30206-0 N54368-0 N117802-0 N18190-0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>U254959</td>\n",
       "      <td>11/15/2019 11:42:35 AM</td>\n",
       "      <td>N34011 N9375 N67397 N7936 N118985 N109453 N103...</td>\n",
       "      <td>N119999-0 N24958-0 N104054-0 N33901-0 N9250-0 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>U499841</td>\n",
       "      <td>11/15/2019 9:08:21 AM</td>\n",
       "      <td>N63858 N26834 N6379 N85484 N15229 N65119 N1047...</td>\n",
       "      <td>N18190-0 N89764-0 N91737-0 N54368-0 N49978-1 N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>U107107</td>\n",
       "      <td>11/15/2019 5:50:31 AM</td>\n",
       "      <td>N12959 N8085 N18389 N3758 N9740 N90543 N129790...</td>\n",
       "      <td>N122944-1 N18190-0 N55801-0 N59297-0 N128045-0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>U492344</td>\n",
       "      <td>11/15/2019 5:02:25 AM</td>\n",
       "      <td>N109183 N48453 N85005 N45706 N98923 N46069 N35...</td>\n",
       "      <td>N64785-0 N82503-0 N32993-0 N122944-0 N29160-0 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   impression_id      uid                    time  \\\n",
       "0              1  U134050   11/15/2019 8:55:22 AM   \n",
       "1              2  U254959  11/15/2019 11:42:35 AM   \n",
       "2              3  U499841   11/15/2019 9:08:21 AM   \n",
       "3              4  U107107   11/15/2019 5:50:31 AM   \n",
       "4              5  U492344   11/15/2019 5:02:25 AM   \n",
       "\n",
       "                                             history  \\\n",
       "0  N12246 N128820 N119226 N4065 N67770 N33446 N10...   \n",
       "1  N34011 N9375 N67397 N7936 N118985 N109453 N103...   \n",
       "2  N63858 N26834 N6379 N85484 N15229 N65119 N1047...   \n",
       "3  N12959 N8085 N18389 N3758 N9740 N90543 N129790...   \n",
       "4  N109183 N48453 N85005 N45706 N98923 N46069 N35...   \n",
       "\n",
       "                                         impressions  \n",
       "0  N91737-0 N30206-0 N54368-0 N117802-0 N18190-0 ...  \n",
       "1  N119999-0 N24958-0 N104054-0 N33901-0 N9250-0 ...  \n",
       "2  N18190-0 N89764-0 N91737-0 N54368-0 N49978-1 N...  \n",
       "3  N122944-1 N18190-0 N55801-0 N59297-0 N128045-0...  \n",
       "4  N64785-0 N82503-0 N32993-0 N122944-0 N29160-0 ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behaviors_valid = cudf.read_csv(os.path.join(data_path_valid , 'behaviors.tsv'),\n",
    "                          header=None,\n",
    "                          names=behaviors_columns,\n",
    "                    sep='\\t',)\n",
    "behaviors_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2mZahZos33C"
   },
   "source": [
    "### News data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ab-vydECs33C",
    "outputId": "9042b9e4-cf53-4104-c829-494c7acd7027"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N88753</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAGH0ET.html</td>\n",
       "      <td>[{\"Label\": \"Prince Philip, Duke of Edinburgh\",...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N45436</td>\n",
       "      <td>news</td>\n",
       "      <td>newsscienceandtechnology</td>\n",
       "      <td>Walmart Slashes Prices on Last-Generation iPads</td>\n",
       "      <td>Apple's new iPad releases bring big deals on l...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AABmf2I.html</td>\n",
       "      <td>[{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...</td>\n",
       "      <td>[{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N23144</td>\n",
       "      <td>health</td>\n",
       "      <td>weightloss</td>\n",
       "      <td>50 Worst Habits For Belly Fat</td>\n",
       "      <td>These seemingly harmless habits are holding yo...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAB19MK.html</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N86255</td>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>Dispose of unwanted prescription drugs during ...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAISxPN.html</td>\n",
       "      <td>[{\"Label\": \"Drug Enforcement Administration\", ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N93187</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJgNsz.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0          1                         2  \\\n",
       "0  N88753  lifestyle           lifestyleroyals   \n",
       "1  N45436       news  newsscienceandtechnology   \n",
       "2  N23144     health                weightloss   \n",
       "3  N86255     health                   medical   \n",
       "4  N93187       news                 newsworld   \n",
       "\n",
       "                                                   3  \\\n",
       "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1    Walmart Slashes Prices on Last-Generation iPads   \n",
       "2                      50 Worst Habits For Belly Fat   \n",
       "3  Dispose of unwanted prescription drugs during ...   \n",
       "4  The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "\n",
       "                                                   4  \\\n",
       "0  Shop the notebooks, jackets, and more that the...   \n",
       "1  Apple's new iPad releases bring big deals on l...   \n",
       "2  These seemingly harmless habits are holding yo...   \n",
       "3                                               <NA>   \n",
       "4  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
       "\n",
       "                                               5  \\\n",
       "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
       "1  https://assets.msn.com/labs/mind/AABmf2I.html   \n",
       "2  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
       "3  https://assets.msn.com/labs/mind/AAISxPN.html   \n",
       "4  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
       "\n",
       "                                                   6  \\\n",
       "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
       "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...   \n",
       "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
       "3  [{\"Label\": \"Drug Enforcement Administration\", ...   \n",
       "4                                                 []   \n",
       "\n",
       "                                                   7  \n",
       "0                                                 []  \n",
       "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...  \n",
       "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
       "3                                                 []  \n",
       "4  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train = cudf.read_csv(os.path.join(data_path_train , 'news.tsv'),\n",
    "                          header=None,\n",
    "                          sep='\\t',)\n",
    "news_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hE2q1J1As33D"
   },
   "outputs": [],
   "source": [
    "news_columns = ['did', 'cat', 'sub_cat', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Unm9xV_2s33D",
    "outputId": "682668a3-f422-4132-c550-f88cc60470b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>cat</th>\n",
       "      <th>sub_cat</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>title_entities</th>\n",
       "      <th>abstract_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N88753</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAGH0ET.html</td>\n",
       "      <td>[{\"Label\": \"Prince Philip, Duke of Edinburgh\",...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N45436</td>\n",
       "      <td>news</td>\n",
       "      <td>newsscienceandtechnology</td>\n",
       "      <td>Walmart Slashes Prices on Last-Generation iPads</td>\n",
       "      <td>Apple's new iPad releases bring big deals on l...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AABmf2I.html</td>\n",
       "      <td>[{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...</td>\n",
       "      <td>[{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N23144</td>\n",
       "      <td>health</td>\n",
       "      <td>weightloss</td>\n",
       "      <td>50 Worst Habits For Belly Fat</td>\n",
       "      <td>These seemingly harmless habits are holding yo...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAB19MK.html</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N86255</td>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>Dispose of unwanted prescription drugs during ...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAISxPN.html</td>\n",
       "      <td>[{\"Label\": \"Drug Enforcement Administration\", ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N93187</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJgNsz.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      did        cat                   sub_cat  \\\n",
       "0  N88753  lifestyle           lifestyleroyals   \n",
       "1  N45436       news  newsscienceandtechnology   \n",
       "2  N23144     health                weightloss   \n",
       "3  N86255     health                   medical   \n",
       "4  N93187       news                 newsworld   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1    Walmart Slashes Prices on Last-Generation iPads   \n",
       "2                      50 Worst Habits For Belly Fat   \n",
       "3  Dispose of unwanted prescription drugs during ...   \n",
       "4  The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Shop the notebooks, jackets, and more that the...   \n",
       "1  Apple's new iPad releases bring big deals on l...   \n",
       "2  These seemingly harmless habits are holding yo...   \n",
       "3                                               <NA>   \n",
       "4  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
       "\n",
       "                                             url  \\\n",
       "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
       "1  https://assets.msn.com/labs/mind/AABmf2I.html   \n",
       "2  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
       "3  https://assets.msn.com/labs/mind/AAISxPN.html   \n",
       "4  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
       "\n",
       "                                      title_entities  \\\n",
       "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
       "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...   \n",
       "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
       "3  [{\"Label\": \"Drug Enforcement Administration\", ...   \n",
       "4                                                 []   \n",
       "\n",
       "                                   abstract_entities  \n",
       "0                                                 []  \n",
       "1  [{\"Label\": \"IPad\", \"Type\": \"J\", \"WikidataId\": ...  \n",
       "2  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
       "3                                                 []  \n",
       "4  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train = cudf.read_csv(os.path.join(data_path_train , 'news.tsv'),\n",
    "                          header=None,\n",
    "                          names=news_columns,\n",
    "                    sep='\\t',)\n",
    "news_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IXaTIUF8s33D",
    "outputId": "a117363a-5ce2-4c79-a7ac-c71d403e8e8d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>cat</th>\n",
       "      <th>sub_cat</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>url</th>\n",
       "      <th>title_entities</th>\n",
       "      <th>abstract_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N88753</td>\n",
       "      <td>lifestyle</td>\n",
       "      <td>lifestyleroyals</td>\n",
       "      <td>The Brands Queen Elizabeth, Prince Charles, an...</td>\n",
       "      <td>Shop the notebooks, jackets, and more that the...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAGH0ET.html</td>\n",
       "      <td>[{\"Label\": \"Prince Philip, Duke of Edinburgh\",...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N23144</td>\n",
       "      <td>health</td>\n",
       "      <td>weightloss</td>\n",
       "      <td>50 Worst Habits For Belly Fat</td>\n",
       "      <td>These seemingly harmless habits are holding yo...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAB19MK.html</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "      <td>[{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N86255</td>\n",
       "      <td>health</td>\n",
       "      <td>medical</td>\n",
       "      <td>Dispose of unwanted prescription drugs during ...</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAISxPN.html</td>\n",
       "      <td>[{\"Label\": \"Drug Enforcement Administration\", ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N93187</td>\n",
       "      <td>news</td>\n",
       "      <td>newsworld</td>\n",
       "      <td>The Cost of Trump's Aid Freeze in the Trenches...</td>\n",
       "      <td>Lt. Ivan Molchanets peeked over a parapet of s...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AAJgNsz.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N75236</td>\n",
       "      <td>health</td>\n",
       "      <td>voices</td>\n",
       "      <td>I Was An NBA Wife. Here's How It Affected My M...</td>\n",
       "      <td>I felt like I was a fraud, and being an NBA wi...</td>\n",
       "      <td>https://assets.msn.com/labs/mind/AACk2N6.html</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{\"Label\": \"National Basketball Association\", ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      did        cat          sub_cat  \\\n",
       "0  N88753  lifestyle  lifestyleroyals   \n",
       "1  N23144     health       weightloss   \n",
       "2  N86255     health          medical   \n",
       "3  N93187       news        newsworld   \n",
       "4  N75236     health           voices   \n",
       "\n",
       "                                               title  \\\n",
       "0  The Brands Queen Elizabeth, Prince Charles, an...   \n",
       "1                      50 Worst Habits For Belly Fat   \n",
       "2  Dispose of unwanted prescription drugs during ...   \n",
       "3  The Cost of Trump's Aid Freeze in the Trenches...   \n",
       "4  I Was An NBA Wife. Here's How It Affected My M...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Shop the notebooks, jackets, and more that the...   \n",
       "1  These seemingly harmless habits are holding yo...   \n",
       "2                                               <NA>   \n",
       "3  Lt. Ivan Molchanets peeked over a parapet of s...   \n",
       "4  I felt like I was a fraud, and being an NBA wi...   \n",
       "\n",
       "                                             url  \\\n",
       "0  https://assets.msn.com/labs/mind/AAGH0ET.html   \n",
       "1  https://assets.msn.com/labs/mind/AAB19MK.html   \n",
       "2  https://assets.msn.com/labs/mind/AAISxPN.html   \n",
       "3  https://assets.msn.com/labs/mind/AAJgNsz.html   \n",
       "4  https://assets.msn.com/labs/mind/AACk2N6.html   \n",
       "\n",
       "                                      title_entities  \\\n",
       "0  [{\"Label\": \"Prince Philip, Duke of Edinburgh\",...   \n",
       "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...   \n",
       "2  [{\"Label\": \"Drug Enforcement Administration\", ...   \n",
       "3                                                 []   \n",
       "4                                                 []   \n",
       "\n",
       "                                   abstract_entities  \n",
       "0                                                 []  \n",
       "1  [{\"Label\": \"Adipose tissue\", \"Type\": \"C\", \"Wik...  \n",
       "2                                                 []  \n",
       "3  [{\"Label\": \"Ukraine\", \"Type\": \"G\", \"WikidataId...  \n",
       "4  [{\"Label\": \"National Basketball Association\", ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_valid = cudf.read_csv(os.path.join(data_path_valid , 'news.tsv'),\n",
    "                          header=None,\n",
    "                          names=news_columns,\n",
    "                    sep='\\t',)\n",
    "news_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvQIOunAs33D"
   },
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Filter out columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9v6XLMkrs33D",
    "outputId": "b4395e52-61f5-4383-93ea-916228f98b71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>did</th>\n",
       "      <th>cat</th>\n",
       "      <th>sub_cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N1</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>N100</td>\n",
       "      <td>finance</td>\n",
       "      <td>markets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>N1000</td>\n",
       "      <td>weather</td>\n",
       "      <td>weathertopstories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N10000</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>celebrity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>N100000</td>\n",
       "      <td>sports</td>\n",
       "      <td>football_nfl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       did            cat            sub_cat\n",
       "0       N1         sports       football_nfl\n",
       "1     N100        finance            markets\n",
       "2    N1000        weather  weathertopstories\n",
       "3   N10000  entertainment          celebrity\n",
       "4  N100000         sports       football_nfl"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_train = news_train.drop(['title', 'abstract', 'url', 'title_entities', 'abstract_entities'],axis = 1)\n",
    "news_valid = news_valid.drop(['title', 'abstract', 'url', 'title_entities', 'abstract_entities'],axis = 1)\n",
    "\n",
    "# Merging news train/valid dataset to have a single view of news and their attributes\n",
    "news = cudf.concat([news_train,news_valid]).drop_duplicates().reset_index().drop(['index'],axis=1)\n",
    "\n",
    "# Freeing up memory by nulling the variables\n",
    "news_train = None\n",
    "news_valid = None\n",
    "\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k3wqyqe5s33E",
    "outputId": "667580fc-3972-45cd-d0e0-99afd62d226c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 750434/750434 [00:02<00:00, 319049.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encoding user id from both train and validation dataframe\n",
    "user_index = {}\n",
    "\n",
    "temp = cudf.concat([behaviors_train['uid'],behaviors_valid['uid']]).unique().to_pandas()\n",
    "for i in tqdm(range(len(temp)),total = len(temp)):\n",
    "    user_index[temp[i]] = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "me1kLmi8s33E"
   },
   "outputs": [],
   "source": [
    "# Replacing uid in the dataset with their respective indexes\n",
    "\n",
    "behaviors_train['uid'] = behaviors_train['uid'].replace([i for i in user_index],[str(user_index[i]) for i in user_index]).astype('int')\n",
    "behaviors_valid['uid'] = behaviors_valid['uid'].replace([i for i in user_index],[str(user_index[i]) for i in user_index]).astype('int')\n",
    "\n",
    "# Freeing up memory by nulling variables\n",
    "user_index = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "791rPG1Rs33E",
    "outputId": "61ad68df-d3e6-4da0-c979-2dee880109f7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 104151/104151 [00:06<00:00, 16238.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encoding news id from the combined news dataframe\n",
    "news_index = {}\n",
    "\n",
    "for n,data in tqdm(news.to_pandas().iterrows(),total = len(news)):\n",
    "    news_index[data['did']] = n + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcEXkrMls33J",
    "outputId": "430b920b-17e2-4dd9-bd30-38d81eee59f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 18/18 [00:00<00:00, 27.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 285/285 [00:00<00:00, 377.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# Encoding new's category and subcategories\n",
    "\n",
    "cat = {}\n",
    "subcat = {}\n",
    "\n",
    "temp = news['cat'].unique()\n",
    "for i in tqdm(range(len(temp)),total = len(temp)):\n",
    "    cat[temp[i]] = i + 1\n",
    "\n",
    "temp = news['sub_cat'].unique()\n",
    "for i in tqdm(range(len(temp)),total = len(temp)):\n",
    "    subcat[temp[i]] = i + 1\n",
    "\n",
    "# Replacing did, cat and sub_cate with their respective indexes in the news dataframe\n",
    "news = news.replace({'did': [i for i in news_index], 'cat': [i for i in cat], 'sub_cat': [i for i in subcat]},{'did': [str(news_index[i]) for i in news_index], 'cat': [str(cat[i]) for i in cat], 'sub_cat': [str(subcat[i]) for i in subcat]}).astype('int')\n",
    "news = news.set_index('did').to_pandas().T.to_dict()\n",
    "\n",
    "# Freeing up memory by nulling variables\n",
    "temp = None\n",
    "cat = None\n",
    "subcat = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unrolling history into multiple columns. Only using 10 most recent news articles from history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, consider the below row in behaviours dataframe\n",
    "\n",
    "|impression_id | uid | time | history | impressions |\n",
    "| :-: | :-: | :-: |:-: |:-: |\n",
    "| 1 | U64099 | 11/19/2019 11:37:45 AM |\tN121133 N104200 N43255 N55860 N128965 N38014 | N78206-0 N26368-1 N7578-1 N58592-0 N19858-0 |\n",
    "\n",
    "We have to convert one history column with many news id to multiple history columns with single news id. \n",
    "\n",
    "| hist_0 | hist_1 | hist_2 | hist_3 | hist_4 | hist_5 |\n",
    "| :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "|\tN121133 | N104200 | N43255 | N55860 | N128965 | N38014 |\n",
    "\n",
    "Finally, we will add the news category and subcategory for these news ids. The row after these transformations would look like this:\n",
    "\n",
    "|impression_id | uid | time | hist_cat_0 | hist_cat_1 | hist_cat_2 | ... | hist_subcat_3 | hist_subcat_4 | hist_subcat_5 | impressions |\n",
    "| :-: | :-: | :-: |:-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| 1 | U64099 | 11/19/2019 11:37:45 AM |\tsports | finance | entertainment | ... | markets | celebrity | football_nfl | N78206-0 N26368-1 N7578-1 N58592-0 N19858-0 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_hist = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = cudf.DataFrame() \n",
    "\n",
    "# Splitting the long string of history into several columns\n",
    "hist[['hist_'+str(i) for i in range(max_hist)]] = behaviors_train.history.str.rsplit(n=max_hist,expand=True).fillna(0)[[i for i in range(1,max_hist+1)]]\n",
    "\n",
    "# Replacing string news id in history with respective indexes\n",
    "hist = hist.replace([i for i in news_index],[str(news_index[i]) for i in news_index]).astype('int')\n",
    "\n",
    "# Appending news category corresponding to these newly created history columns\n",
    "behaviors_train[['hist_cat_'+str(i) for i in range(max_hist)]] = hist.replace([int(i) for i in news],[int(news[i]['cat']) for i in news])\n",
    "\n",
    "# Appending news sub-category corresponding to these newly created history columns\n",
    "behaviors_train[['hist_subcat_'+str(i) for i in range(max_hist)]] = hist.replace([int(i) for i in news],[int(news[i]['sub_cat']) for i in news])\n",
    "\n",
    "# Creating a column for the length of history \n",
    "behaviors_train['hist_count'] = behaviors_train.history.str.count(\" \")+1\n",
    "\n",
    "# Dropping the long string history column\n",
    "behaviors_train = behaviors_train.drop(['history'],axis=1)\n",
    "\n",
    "# Freeing up memory by nulling variables\n",
    "hist = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating the same for validation set\n",
    "hist = cudf.DataFrame()\n",
    "\n",
    "hist[['hist_'+str(i) for i in range(max_hist)]] = behaviors_valid.history.str.rsplit(n=max_hist,expand=True).fillna(0)[[i for i in range(1,max_hist+1)]]\n",
    "\n",
    "hist = hist.replace([i for i in news_index],[str(news_index[i]) for i in news_index]).astype('int')\n",
    "\n",
    "behaviors_valid[['hist_cat_'+str(i) for i in range(max_hist)]] = hist.replace([int(i) for i in news],[int(news[i]['cat']) for i in news])\n",
    "\n",
    "behaviors_valid[['hist_subcat_'+str(i) for i in range(max_hist)]] = hist.replace([int(i) for i in news],[int(news[i]['sub_cat']) for i in news])\n",
    "\n",
    "behaviors_valid['hist_count'] = behaviors_valid.history.str.count(\" \")+1\n",
    "\n",
    "behaviors_valid = behaviors_valid.drop(['history'],axis=1)\n",
    "\n",
    "hist = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unroll items in impression column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, consider the below expanded history column row from the behaviours dataframe:\n",
    "\n",
    "|impression_id | uid | time | hist_cat_0 | hist_cat_1 | hist_cat_2 | ... | hist_subcat_3 | hist_subcat_4 | hist_subcat_5 | impressions |\n",
    "| :-: | :-: | :-: |:-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| 1 | U64099 | 11/19/2019 11:37:45 AM |\tsports | finance | entertainment | ... | markets | celebrity | football_nfl | N78206-0 N26368-1 N7578-1 N58592-0 N19858-0 |\n",
    "\n",
    "The impression column contains the positive and negetive samples as a long string.\n",
    "\n",
    "After unrolling one row of impressions into multiple rows, the resulting dataframe would look like this:\n",
    "\n",
    "|impression_id | uid | time | hist_cat_0 | hist_cat_1 | hist_cat_2 | ... | hist_subcat_3 | hist_subcat_4 | hist_subcat_5 | impressions | label |\n",
    "| :-: | :-: | :-: |:-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: | :-: |\n",
    "| 1 | U64099 | 11/19/2019 11:37:45 AM |\tsports | finance | entertainment | ... | markets | celebrity | football_nfl | N78206 | 0 |\n",
    "| 1 | U64099 | 11/19/2019 11:37:45 AM |\tsports | finance | entertainment | ... | markets | celebrity | football_nfl | N26368 | 1 |\n",
    "| 1 | U64099 | 11/19/2019 11:37:45 AM |\tsports | finance | entertainment | ... | markets | celebrity | football_nfl | N7578 | 1 |\n",
    "| 1 | U64099 | 11/19/2019 11:37:45 AM |\tsports | finance | entertainment | ... | markets | celebrity | football_nfl | N58592 | 0 |\n",
    "| 1 | U64099 | 11/19/2019 11:37:45 AM |\tsports | finance | entertainment | ... | markets | celebrity | football_nfl | N19858 | 0 |\n",
    "\n",
    "Note that all the 5 generated rows have the same impression_id, uid, time and history data columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_impr = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting impressions column to dictionary of lists\n",
    "# For train dataset\n",
    "impr_train = behaviors_train.set_index('impression_id').impressions.to_pandas().str.split()\n",
    "impr_train = impr_train.to_dict()\n",
    "behaviors_train = behaviors_train.drop(['impressions'],axis=1)\n",
    "\n",
    "# For validation dataset\n",
    "impr_valid = behaviors_valid.set_index('impression_id').impressions.to_pandas().str.split()\n",
    "impr_valid = impr_valid.to_dict()\n",
    "behaviors_valid = behaviors_valid.drop(['impressions'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_ratio = -1 # ratio of neg-to-pos samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2232748/2232748 [04:15<00:00, 8748.54it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imp_id</th>\n",
       "      <th>label</th>\n",
       "      <th>impr_cat</th>\n",
       "      <th>impr_subcat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>84769</td>\n",
       "      <td>84769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38819</td>\n",
       "      <td>38819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>82639</td>\n",
       "      <td>82639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>67404</td>\n",
       "      <td>67404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32985</td>\n",
       "      <td>32985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imp_id label impr_cat impr_subcat\n",
       "0       1     0    84769       84769\n",
       "1       1     0    38819       38819\n",
       "2       1     0    82639       82639\n",
       "3       1     0    67404       67404\n",
       "4       1     0    32985       32985"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For train set\n",
    "\n",
    "imp_id = []\n",
    "imp_list = []\n",
    "imp_label = []\n",
    "for i in tqdm(impr_train,total = len(impr_train)):\n",
    "    imp, label = np.transpose([[news_index[imp.split('-')[0]],imp.split('-')[1]] for imp in impr_train[i]])\n",
    "    pos = (label == '1').sum()\n",
    "    neg = 0\n",
    "    for j in range(min(len(imp),max_impr)):\n",
    "        if label[j] == '0' and np_ratio > -1:\n",
    "            if neg <= pos*np_ratio :\n",
    "                imp_id.append(i)\n",
    "                imp_list.append(imp[j])\n",
    "                imp_label.append(label[j])\n",
    "                neg+=1\n",
    "        else:\n",
    "            imp_id.append(i)\n",
    "            imp_list.append(imp[j])\n",
    "            imp_label.append(label[j])\n",
    "\n",
    "impr_train = None \n",
    "\n",
    "# Creating a new gdf with impression id, news id and its label\n",
    "impressions_train = cudf.DataFrame({'imp_id': imp_id,'impr': imp_list,'label': imp_label})\n",
    "\n",
    "# Appending news category corresponding to above impression news in the above created DataFrame\n",
    "impressions_train['impr_cat'] = impressions_train['impr'].replace([int(i) for i in news],[int(news[i]['cat']) for i in news])\n",
    "\n",
    "# Appending news sub-category corresponding to above impression news in above created DataFrame\n",
    "impressions_train['impr_subcat'] = impressions_train['impr'].replace([int(i) for i in news],[int(news[i]['sub_cat']) for i in news])\n",
    "\n",
    "# Droping impr columns as news data is added for it.\n",
    "impressions_train = impressions_train.drop(['impr'],axis=1)\n",
    "\n",
    "impressions_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 376471/376471 [00:41<00:00, 9112.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imp_id</th>\n",
       "      <th>label</th>\n",
       "      <th>impr_cat</th>\n",
       "      <th>impr_subcat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96774</td>\n",
       "      <td>96774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>42250</td>\n",
       "      <td>42250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>63649</td>\n",
       "      <td>63649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15784</td>\n",
       "      <td>15784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31476</td>\n",
       "      <td>31476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imp_id label impr_cat impr_subcat\n",
       "0       1     0    96774       96774\n",
       "1       1     0    42250       42250\n",
       "2       1     0    63649       63649\n",
       "3       1     0    15784       15784\n",
       "4       1     0    31476       31476"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For validation set\n",
    "\n",
    "imp_id = []\n",
    "imp_list = []\n",
    "imp_label = []\n",
    "for i in tqdm(impr_valid,total = len(impr_valid)):\n",
    "    imp, label = np.transpose([[news_index[imp.split('-')[0]],imp.split('-')[1]] for imp in impr_valid[i]])\n",
    "    pos = (label == '1').sum()\n",
    "    neg = 0\n",
    "    for j in range(min(len(imp),max_impr)):\n",
    "        if label[j] == '0' and np_ratio > -1:\n",
    "            if neg <= pos*np_ratio :\n",
    "                imp_id.append(i)\n",
    "                imp_list.append(imp[j])\n",
    "                imp_label.append(label[j])\n",
    "                neg+=1\n",
    "        else:\n",
    "            imp_id.append(i)\n",
    "            imp_list.append(imp[j])\n",
    "            imp_label.append(label[j])\n",
    "\n",
    "impr_valid = None \n",
    "\n",
    "impressions_valid = cudf.DataFrame({'imp_id': imp_id,'impr': imp_list,'label': imp_label})\n",
    "impressions_valid['impr_cat'] = impressions_valid['impr'].replace([int(i) for i in news],[int(news[i]['cat']) for i in news])\n",
    "impressions_valid['impr_subcat'] = impressions_valid['impr'].replace([int(i) for i in news],[int(news[i]['sub_cat']) for i in news])\n",
    "impressions_valid = impressions_valid.drop(['impr'],axis=1)\n",
    "impressions_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeing up memory by nulling variables\n",
    "imp_id = None\n",
    "imp_list = None\n",
    "imp_label = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge behaviors and news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training set\n",
    "rmm.reinitialize(managed_memory=True)\n",
    "\n",
    "final_data = impressions_train.merge(behaviors_train,left_on = ['imp_id'],right_on = ['impression_id']).drop(['imp_id'],axis=1)\n",
    "final_data = cudf.concat([final_data.drop(['time'],axis=1).astype('int'),final_data['time']],axis=1)\n",
    "final_data.to_parquet(os.path.join(data_input_path, 'train.parquet'), compression = None)\n",
    "\n",
    "# Freeing up memory by nulling variables\n",
    "final_data=None\n",
    "impressions_train = None\n",
    "behaviors_train = None\n",
    "\n",
    "#client.run(_rmm_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For validation set\n",
    "\n",
    "final_data = impressions_valid.merge(behaviors_valid,left_on = ['imp_id'],right_on = ['impression_id']).drop(['imp_id'],axis=1)\n",
    "final_data = cudf.concat([final_data.drop(['time'],axis=1).astype('int'),final_data['time']],axis=1)\n",
    "final_data.to_parquet(os.path.join(data_input_path, 'valid.parquet'),compression = None)\n",
    "\n",
    "# Freeing up memory by nulling variables\n",
    "final_data=None\n",
    "impressions_valid = None\n",
    "behaviors_valid = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train.parquet` and `test.parquet` are the pre-process datasets that we can use for feature engineering\n",
    "\n",
    "create timebased features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring features of train set that we created\n",
    "\n",
    "cat_features = [\n",
    " 'hist_cat_0',\n",
    " 'hist_subcat_0',\n",
    " 'hist_cat_1',\n",
    " 'hist_subcat_1',\n",
    " 'hist_cat_2',\n",
    " 'hist_subcat_2',\n",
    " 'hist_cat_3',\n",
    " 'hist_subcat_3',\n",
    " 'hist_cat_4',\n",
    " 'hist_subcat_4',\n",
    " 'hist_cat_5',\n",
    " 'hist_subcat_5',\n",
    " 'hist_cat_6',\n",
    " 'hist_subcat_6',\n",
    " 'hist_cat_7',\n",
    " 'hist_subcat_7',\n",
    " 'hist_cat_8',\n",
    " 'hist_subcat_8',\n",
    " 'hist_cat_9',\n",
    " 'hist_subcat_9',\n",
    " 'impr_cat',\n",
    " 'impr_subcat',\n",
    " 'impression_id',\n",
    " 'uid']\n",
    "\n",
    "cont_features = ['hist_count']\n",
    "\n",
    "labels = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating time based features by extracting the relevant elements using cuDF\n",
    "\n",
    "datetime = nvt.ColumnGroup(['time']) >> (lambda col: cudf.to_datetime(col,format=\"%m/%d/%Y %I:%M:%S %p\"))\n",
    "\n",
    "hour = datetime >> (lambda col: col.dt.hour) >> nvt.ops.Rename(postfix = '_hour')\n",
    "minute = datetime >> (lambda col: col.dt.minute) >> nvt.ops.Rename(postfix = '_minute')\n",
    "seconds = datetime >> (lambda col: col.dt.second) >> nvt.ops.Rename(postfix = '_second')\n",
    "\n",
    "weekday = datetime >> (lambda col: col.dt.weekday) >> nvt.ops.Rename(postfix = '_wd')\n",
    "day = datetime >> (lambda col: cudf.to_datetime(col, unit='s').dt.day) >> nvt.ops.Rename(postfix = '_day')\n",
    "\n",
    "week = day >> (lambda col: (col/7).floor().astype('int')) >> nvt.ops.Rename(postfix = '_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = cat_features + hour + minute + seconds + weekday + day + week + datetime >> nvt.ops.Categorify(out_path = data_output_path)\n",
    "cont_features = cont_features >> nvt.ops.FillMissing() >> nvt.ops.NormalizeMinMax()\n",
    "labels = ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the complete workflow pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1281pt\" height=\"692pt\"\n",
       " viewBox=\"0.00 0.00 1281.27 692.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 688)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-688 1277.27,-688 1277.27,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"118.29\" cy=\"-306\" rx=\"118.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"118.29\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[hist_count]</text>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>18</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"227.29\" cy=\"-234\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"227.29\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;18 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>0&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M144.12,-288.41C159.1,-278.79 178.12,-266.58 194.19,-256.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"196.24,-259.1 202.77,-250.75 192.46,-253.21 196.24,-259.1\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"563.29\" cy=\"-594\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"563.29\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"510.29\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"510.29\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M504.04,-589.35C431.35,-583.64 313.94,-569.95 283.29,-540 254.36,-511.73 264.29,-491.45 264.29,-451 264.29,-451 264.29,-451 264.29,-377 264.29,-281.55 404.93,-249.26 473.53,-239.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"474.07,-242.64 483.49,-237.81 473.11,-235.71 474.07,-242.64\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"353.29\" cy=\"-522\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"353.29\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M524.28,-580C489.66,-568.46 438.93,-551.55 401.72,-539.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"402.68,-535.77 392.09,-535.93 400.47,-542.42 402.68,-535.77\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"493.29\" cy=\"-522\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"493.29\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;7 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>1&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M546.7,-576.41C537.81,-567.52 526.7,-556.41 516.92,-546.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"519.31,-544.07 509.76,-539.47 514.36,-549.02 519.31,-544.07\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"633.29\" cy=\"-522\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"633.29\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;9 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>1&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M579.88,-576.41C588.77,-567.52 599.88,-556.41 609.66,-546.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"612.22,-549.02 616.82,-539.47 607.27,-544.07 612.22,-549.02\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"773.29\" cy=\"-522\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"773.29\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;11 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>1&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M602.3,-580C636.92,-568.46 687.65,-551.55 724.86,-539.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"726.11,-542.42 734.49,-535.93 723.9,-535.77 726.11,-542.42\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>16</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"913.29\" cy=\"-522\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"913.29\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;16 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>1&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M614.54,-584.11C670.81,-574.16 763.74,-557.18 843.29,-540 848.21,-538.94 853.31,-537.79 858.41,-536.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"859.25,-540.01 868.18,-534.31 857.65,-533.19 859.25,-540.01\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"563.29\" cy=\"-666\" rx=\"91.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"563.29\" y=\"-662.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[time]</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>6&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M563.29,-647.7C563.29,-639.98 563.29,-630.71 563.29,-622.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"566.79,-622.1 563.29,-612.1 559.79,-622.1 566.79,-622.1\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"483.29\" cy=\"-162\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"483.29\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;8 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>2&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M503.89,-216.41C500.78,-208.34 496.96,-198.43 493.45,-189.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"496.69,-188.03 489.83,-179.96 490.16,-190.55 496.69,-188.03\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>19</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"716.29\" cy=\"-450\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"716.29\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>19&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M715.49,-431.88C713.87,-412.86 708.98,-381.96 694.29,-360 656.71,-303.84 584.54,-266.06 542.63,-247.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"543.73,-244.43 533.16,-243.74 540.99,-250.87 543.73,-244.43\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>15</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1026.29\" cy=\"-306\" rx=\"246.96\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1026.29\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[hist_cat_0, hist_subcat_0, hist_cat_1...]</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>15&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M914.96,-289.9C798.38,-274.08 621.97,-250.15 546.56,-239.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"546.98,-236.45 536.6,-238.57 546.04,-243.38 546.98,-236.45\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>14</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"345.29\" cy=\"-378\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"345.29\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>14&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M353.79,-360.06C364.22,-340.65 383.48,-308.83 407.29,-288 427.9,-269.97 455.72,-256.13 477.25,-247.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"478.69,-250.31 486.65,-243.32 476.07,-243.82 478.69,-250.31\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"637.29\" cy=\"-378\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"637.29\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;2 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>10&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M625.37,-360.3C611.99,-341.94 589.26,-311.86 567.29,-288 556.93,-276.75 544.6,-265.09 534.05,-255.58\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"536.2,-252.81 526.4,-248.77 531.54,-258.03 536.2,-252.81\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>13</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"872.29\" cy=\"-450\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"872.29\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;2 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>13&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M854.43,-433.13C818.52,-401.86 734.08,-331.55 653.29,-288 617.95,-268.95 574.31,-253.87 544.6,-244.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"545.29,-241.3 534.71,-241.77 543.27,-248 545.29,-241.3\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>17</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"493.29\" cy=\"-450\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"493.29\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;2 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>17&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M471.3,-433.82C459.71,-424.43 446.61,-411.27 440.29,-396 434.17,-381.22 438.86,-375.94 440.29,-360 443.19,-327.61 437.69,-316.53 453.29,-288 460.57,-274.68 472.44,-262.84 483.47,-253.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"485.93,-256.27 491.65,-247.36 481.61,-250.76 485.93,-256.27\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"510.29\" cy=\"-378\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"510.29\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;12 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>17&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M497.4,-432.05C499.3,-424.26 501.59,-414.82 503.71,-406.08\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"507.14,-406.82 506.09,-396.28 500.33,-405.17 507.14,-406.82\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"510.29\" cy=\"-306\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"510.29\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;2 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>4&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M510.29,-287.7C510.29,-279.98 510.29,-270.71 510.29,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"513.79,-262.1 510.29,-252.1 506.79,-262.1 513.79,-262.1\"/>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;14 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>3&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M352.32,-503.87C350.96,-479.67 348.46,-435.21 346.83,-406.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"350.31,-405.98 346.26,-396.19 343.33,-406.37 350.31,-405.98\"/>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;4 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>12&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M510.29,-359.7C510.29,-351.98 510.29,-342.71 510.29,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"513.79,-334.1 510.29,-324.1 506.79,-334.1 513.79,-334.1\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"340.29\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"340.29\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>21</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"340.29\" cy=\"-18\" rx=\"252.66\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"340.29\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">output cols=[time_hour, hist_cat_0, hist_subcat_0...]</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;21 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>5&#45;&gt;21</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M340.29,-71.7C340.29,-63.98 340.29,-54.71 340.29,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"343.79,-46.1 340.29,-36.1 336.79,-46.1 343.79,-46.1\"/>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;5 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>8&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M453.31,-146.33C429.02,-134.43 394.94,-117.75 370.57,-105.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"371.94,-102.6 361.42,-101.34 368.86,-108.88 371.94,-102.6\"/>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>20</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"253.29\" cy=\"-162\" rx=\"96.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"253.29\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">NormalizeMinMax</text>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;5 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>20&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M273.91,-144.41C286.47,-134.3 302.6,-121.32 315.81,-110.69\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"318.01,-113.42 323.61,-104.42 313.62,-107.96 318.01,-113.42\"/>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;17 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>7&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M493.29,-503.7C493.29,-495.98 493.29,-486.71 493.29,-478.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"496.79,-478.1 493.29,-468.1 489.79,-478.1 496.79,-478.1\"/>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M633.77,-503.87C634.45,-479.67 635.71,-435.21 636.52,-406.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"640.02,-406.28 636.81,-396.19 633.03,-406.09 640.02,-406.28\"/>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;19 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>11&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M759.78,-504.41C752.75,-495.78 744.03,-485.06 736.24,-475.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"738.73,-473.01 729.7,-467.47 733.3,-477.43 738.73,-473.01\"/>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;13 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>16&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M903.36,-504.05C898.53,-495.8 892.61,-485.7 887.25,-476.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"890.2,-474.65 882.12,-467.79 884.16,-478.19 890.2,-474.65\"/>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;20 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>18&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M233.58,-216.05C236.51,-208.18 240.06,-198.62 243.34,-189.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"246.67,-190.87 246.87,-180.28 240.11,-188.43 246.67,-190.87\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7d6838ef8970>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = cat_features + cont_features\n",
    "output.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = nvt.Workflow(cat_features + cont_features + labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a nvt.Dataset from parquet file that was created in step 4.\n",
    "\n",
    "data_train = nvt.Dataset(os.path.join(data_input_path, \"train.parquet\"), engine=\"parquet\",part_size=\"256MB\")\n",
    "data_valid = nvt.Dataset(os.path.join(data_input_path, \"valid.parquet\"), engine=\"parquet\",part_size=\"256MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dtypes={}\n",
    "\n",
    "for col in cat_features.columns:\n",
    "    dict_dtypes[col] = np.int64\n",
    "\n",
    "for col in cont_features.columns:\n",
    "    dict_dtypes[col] = np.float32\n",
    "\n",
    "for col in labels:\n",
    "    dict_dtypes[col] = np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the workflow on the training set to record the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 59s, sys: 19.6 s, total: 2min 18s\n",
      "Wall time: 2min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proc.fit(data_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply the transformation to the dataset and persist it to disk as parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 20s, sys: 53.8 s, total: 4min 14s\n",
      "Wall time: 4min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# For training set\n",
    "proc.transform(data_train).to_parquet(output_path= output_train_path,\n",
    "                                shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                dtypes=dict_dtypes,\n",
    "                                out_files_per_proc=10,\n",
    "                                cats = cat_features.columns,\n",
    "                                conts = cont_features.columns,\n",
    "                                labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.7 s, sys: 8.82 s, total: 41.6 s\n",
      "Wall time: 41.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# For validation set\n",
    "proc.transform(data_valid).to_parquet(output_path= output_valid_path,\n",
    "                                shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                dtypes=dict_dtypes,\n",
    "                                out_files_per_proc=10,\n",
    "                                cats = cat_features.columns,\n",
    "                                conts = cont_features.columns,\n",
    "                                labels = labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the NVTabular processed parquet files and look at our first NVTabular pre-processed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_hour</th>\n",
       "      <th>hist_cat_0</th>\n",
       "      <th>hist_subcat_0</th>\n",
       "      <th>hist_cat_1</th>\n",
       "      <th>hist_subcat_1</th>\n",
       "      <th>hist_cat_2</th>\n",
       "      <th>hist_subcat_2</th>\n",
       "      <th>hist_cat_3</th>\n",
       "      <th>hist_subcat_3</th>\n",
       "      <th>hist_cat_4</th>\n",
       "      <th>...</th>\n",
       "      <th>impression_id</th>\n",
       "      <th>uid</th>\n",
       "      <th>time_minute</th>\n",
       "      <th>time_second</th>\n",
       "      <th>time_wd</th>\n",
       "      <th>time_day</th>\n",
       "      <th>time_day_week</th>\n",
       "      <th>time</th>\n",
       "      <th>hist_count</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>128</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>1790</td>\n",
       "      <td>69501</td>\n",
       "      <td>26</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>47170</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>187</td>\n",
       "      <td>6</td>\n",
       "      <td>137</td>\n",
       "      <td>12</td>\n",
       "      <td>149</td>\n",
       "      <td>6</td>\n",
       "      <td>97</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>3185</td>\n",
       "      <td>555888</td>\n",
       "      <td>43</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>48229</td>\n",
       "      <td>0.019975</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>172</td>\n",
       "      <td>12</td>\n",
       "      <td>176</td>\n",
       "      <td>3</td>\n",
       "      <td>154</td>\n",
       "      <td>12</td>\n",
       "      <td>173</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>627819</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>50042</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>165</td>\n",
       "      <td>17</td>\n",
       "      <td>232</td>\n",
       "      <td>13</td>\n",
       "      <td>159</td>\n",
       "      <td>12</td>\n",
       "      <td>165</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2921</td>\n",
       "      <td>180321</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>49602</td>\n",
       "      <td>0.061174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>172</td>\n",
       "      <td>15</td>\n",
       "      <td>219</td>\n",
       "      <td>14</td>\n",
       "      <td>87</td>\n",
       "      <td>12</td>\n",
       "      <td>171</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>418873</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>49867</td>\n",
       "      <td>0.011236</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_hour  hist_cat_0  hist_subcat_0  hist_cat_1  hist_subcat_1  \\\n",
       "0          4           8            128           3             49   \n",
       "1          4           5            187           6            137   \n",
       "2         12          12            172          12            176   \n",
       "3          8          12            165          17            232   \n",
       "4         11          12            172          15            219   \n",
       "\n",
       "   hist_cat_2  hist_subcat_2  hist_cat_3  hist_subcat_3  hist_cat_4  ...  \\\n",
       "0           3             56           3             49          15  ...   \n",
       "1          12            149           6             97           5  ...   \n",
       "2           3            154          12            173          14  ...   \n",
       "3          13            159          12            165           4  ...   \n",
       "4          14             87          12            171          13  ...   \n",
       "\n",
       "   impression_id     uid  time_minute  time_second  time_wd  time_day  \\\n",
       "0           1790   69501           26            9        2         4   \n",
       "1           3185  555888           43           48        2         4   \n",
       "2             65  627819            9            1        2         4   \n",
       "3           2921  180321            5            1        2         4   \n",
       "4            274  418873            1            6        2         4   \n",
       "\n",
       "   time_day_week   time  hist_count  label  \n",
       "0              1  47170    0.007491    0.0  \n",
       "1              1  48229    0.019975    0.0  \n",
       "2              1  50042    0.009988    0.0  \n",
       "3              1  49602    0.061174    0.0  \n",
       "4              1  49867    0.011236    0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = dask_cudf.read_parquet(os.path.join(output_train_path, '*.parquet'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_stats': [{'file_name': '0.1e8e8a37f0a64d889d311abee99c8b56.parquet',\n",
       "   'num_rows': 7717331},\n",
       "  {'file_name': '1.17ded3b36f454311968ae752870370d1.parquet',\n",
       "   'num_rows': 7720295},\n",
       "  {'file_name': '2.5bb8b372ece24812aeee5bcfd8cd7e2b.parquet',\n",
       "   'num_rows': 7716484},\n",
       "  {'file_name': '3.3f02b54c086b492cb52d84a81c11a6ac.parquet',\n",
       "   'num_rows': 7717967},\n",
       "  {'file_name': '4.6e07d4ea58584bd9b0cb319fee954da9.parquet',\n",
       "   'num_rows': 7719456},\n",
       "  {'file_name': '5.a9814ad8096740cb88df9877e58319c4.parquet',\n",
       "   'num_rows': 7713384},\n",
       "  {'file_name': '6.0b864c59445548b0839975a7a123e50f.parquet',\n",
       "   'num_rows': 7716111},\n",
       "  {'file_name': '7.cff15b649b94464a99d18a36cb59f75e.parquet',\n",
       "   'num_rows': 7718793},\n",
       "  {'file_name': '8.6d6732cd59e8487f8f6325c9e7ac45f2.parquet',\n",
       "   'num_rows': 7718962},\n",
       "  {'file_name': '9.77e716a548714b7c81eb86af6db9664d.parquet',\n",
       "   'num_rows': 7716644}],\n",
       " 'cats': [{'col_name': 'time_hour', 'index': 0},\n",
       "  {'col_name': 'hist_cat_0', 'index': 1},\n",
       "  {'col_name': 'hist_subcat_0', 'index': 2},\n",
       "  {'col_name': 'hist_cat_1', 'index': 3},\n",
       "  {'col_name': 'hist_subcat_1', 'index': 4},\n",
       "  {'col_name': 'hist_cat_2', 'index': 5},\n",
       "  {'col_name': 'hist_subcat_2', 'index': 6},\n",
       "  {'col_name': 'hist_cat_3', 'index': 7},\n",
       "  {'col_name': 'hist_subcat_3', 'index': 8},\n",
       "  {'col_name': 'hist_cat_4', 'index': 9},\n",
       "  {'col_name': 'hist_subcat_4', 'index': 10},\n",
       "  {'col_name': 'hist_cat_5', 'index': 11},\n",
       "  {'col_name': 'hist_subcat_5', 'index': 12},\n",
       "  {'col_name': 'hist_cat_6', 'index': 13},\n",
       "  {'col_name': 'hist_subcat_6', 'index': 14},\n",
       "  {'col_name': 'hist_cat_7', 'index': 15},\n",
       "  {'col_name': 'hist_subcat_7', 'index': 16},\n",
       "  {'col_name': 'hist_cat_8', 'index': 17},\n",
       "  {'col_name': 'hist_subcat_8', 'index': 18},\n",
       "  {'col_name': 'hist_cat_9', 'index': 19},\n",
       "  {'col_name': 'hist_subcat_9', 'index': 20},\n",
       "  {'col_name': 'impr_cat', 'index': 21},\n",
       "  {'col_name': 'impr_subcat', 'index': 22},\n",
       "  {'col_name': 'impression_id', 'index': 23},\n",
       "  {'col_name': 'uid', 'index': 24},\n",
       "  {'col_name': 'time_minute', 'index': 25},\n",
       "  {'col_name': 'time_second', 'index': 26},\n",
       "  {'col_name': 'time_wd', 'index': 27},\n",
       "  {'col_name': 'time_day', 'index': 28},\n",
       "  {'col_name': 'time_day_week', 'index': 29},\n",
       "  {'col_name': 'time', 'index': 30}],\n",
       " 'conts': [{'col_name': 'hist_count', 'index': 31}],\n",
       " 'labels': [{'col_name': 'label', 'index': 32}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join(output_train_path, '_metadata.json'),'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hist_cat_0': (18, 16),\n",
       " 'hist_cat_1': (18, 16),\n",
       " 'hist_cat_2': (19, 16),\n",
       " 'hist_cat_3': (18, 16),\n",
       " 'hist_cat_4': (18, 16),\n",
       " 'hist_cat_5': (18, 16),\n",
       " 'hist_cat_6': (18, 16),\n",
       " 'hist_cat_7': (18, 16),\n",
       " 'hist_cat_8': (17, 16),\n",
       " 'hist_cat_9': (17, 16),\n",
       " 'hist_subcat_0': (235, 34),\n",
       " 'hist_subcat_1': (239, 34),\n",
       " 'hist_subcat_2': (236, 34),\n",
       " 'hist_subcat_3': (235, 34),\n",
       " 'hist_subcat_4': (229, 34),\n",
       " 'hist_subcat_5': (224, 33),\n",
       " 'hist_subcat_6': (225, 33),\n",
       " 'hist_subcat_7': (219, 33),\n",
       " 'hist_subcat_8': (213, 32),\n",
       " 'hist_subcat_9': (199, 31),\n",
       " 'impr_cat': (26708, 482),\n",
       " 'impr_subcat': (26708, 482),\n",
       " 'impression_id': (2232749, 512),\n",
       " 'time': (90397, 512),\n",
       " 'time_day': (7, 16),\n",
       " 'time_day_week': (3, 16),\n",
       " 'time_hour': (16, 16),\n",
       " 'time_minute': (61, 16),\n",
       " 'time_second': (61, 16),\n",
       " 'time_wd': (6, 16),\n",
       " 'uid': (711223, 512)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nvtabular.ops import get_embedding_sizes\n",
    "embeddings_simple_time = get_embedding_sizes(proc)\n",
    "embeddings_simple_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16,\n",
       " 18,\n",
       " 235,\n",
       " 18,\n",
       " 239,\n",
       " 19,\n",
       " 236,\n",
       " 18,\n",
       " 235,\n",
       " 18,\n",
       " 229,\n",
       " 18,\n",
       " 224,\n",
       " 18,\n",
       " 225,\n",
       " 18,\n",
       " 219,\n",
       " 17,\n",
       " 213,\n",
       " 17,\n",
       " 199,\n",
       " 26708,\n",
       " 26708,\n",
       " 2232749,\n",
       " 711223,\n",
       " 61,\n",
       " 61,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 90397]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reformatting the above output for ease of copy paste in HugeCTRs config.json\n",
    "\n",
    "embedding_size_str_simple_time = [embeddings_simple_time[x][0] for x in cat_features.columns]\n",
    "embedding_size_str_simple_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count and target based feature encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating directories for the processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our worker and output directories\n",
    "dask_workdir = os.path.join(BASE_DIR, \"workdir\")\n",
    "\n",
    "# Mapping our processed_nvt output directories as the input directories for new workflow.\n",
    "data_input_path = os.path.join(BASE_DIR, \"dataset\")\n",
    "\n",
    "# Defining new directories for output\n",
    "data_output_path = os.path.join(BASE_DIR, \"processed_ce-te\")\n",
    "output_train_path = os.path.join(data_output_path, \"train\")\n",
    "output_valid_path = os.path.join(data_output_path, \"valid\")\n",
    "\n",
    "# Creating and cleaning our worker/output directories\n",
    "try:\n",
    "    # Checking if BASE_DIR exists\n",
    "    if not os.path.isdir(BASE_DIR):\n",
    "        os.mkdir(BASE_DIR)\n",
    "\n",
    "    # Checking if we have a clean worker space for Dask\n",
    "    if os.path.isdir(dask_workdir):\n",
    "        shutil.rmtree(dask_workdir)\n",
    "    os.mkdir(dask_workdir)\n",
    "\n",
    "    # Checking if we have a clean output path for our new dataset\n",
    "    if os.path.isdir(data_output_path):\n",
    "        shutil.rmtree(data_output_path)\n",
    "\n",
    "    os.mkdir(data_output_path)\n",
    "    os.mkdir(output_train_path)\n",
    "    os.mkdir(output_valid_path)\n",
    "\n",
    "except OSError:\n",
    "    print (\"Creation of the directories failed\")\n",
    "else:\n",
    "    print (\"Successfully created the directories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features from prior dataset\n",
    "cat_features = ['hist_cat_0',\n",
    " 'hist_subcat_0',\n",
    " 'hist_cat_1',\n",
    " 'hist_subcat_1',\n",
    " 'hist_cat_2',\n",
    " 'hist_subcat_2',\n",
    " 'hist_cat_3',\n",
    " 'hist_subcat_3',\n",
    " 'hist_cat_4',\n",
    " 'hist_subcat_4',\n",
    " 'hist_cat_5',\n",
    " 'hist_subcat_5',\n",
    " 'hist_cat_6',\n",
    " 'hist_subcat_6',\n",
    " 'hist_cat_7',\n",
    " 'hist_subcat_7',\n",
    " 'hist_cat_8',\n",
    " 'hist_subcat_8',\n",
    " 'hist_cat_9',\n",
    " 'hist_subcat_9',\n",
    " 'impr_cat',\n",
    " 'impr_subcat',\n",
    " 'impression_id',\n",
    " 'uid',]\n",
    "\n",
    "cont_features = ['hist_count']\n",
    "\n",
    "labels = ['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "count encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of columns to use for encoding\n",
    "max_hist = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cat_count(\n",
    "         hist_cat_0,\n",
    "         hist_cat_1,\n",
    "         hist_cat_2,\n",
    "         hist_cat_3,\n",
    "         hist_cat_4,\n",
    "         hist_cat_5,\n",
    "         hist_cat_6,\n",
    "         hist_cat_7,\n",
    "         hist_cat_8,\n",
    "         hist_cat_9,\n",
    "         impr_cat,\n",
    "         impr_cat_count,\n",
    "         k):\n",
    "\n",
    "    # Loop iterates over each row containing the listed categories\n",
    "    for i, temp in enumerate(zip(hist_cat_0,\n",
    "                                 hist_cat_1,\n",
    "                                 hist_cat_2,\n",
    "                                 hist_cat_3,\n",
    "                                 hist_cat_4,\n",
    "                                 hist_cat_5,\n",
    "                                 hist_cat_6,\n",
    "                                 hist_cat_7,\n",
    "                                 hist_cat_8,\n",
    "                                 hist_cat_9,\n",
    "                                 impr_cat,\n",
    "                                )):\n",
    "\n",
    "        # Counting the number of history categories that matches with impression category\n",
    "        for j in temp[:-1]:\n",
    "            if j == temp[-1]:\n",
    "                k += 1\n",
    "\n",
    "        # Update the impression category count in corresponding row\n",
    "        impr_cat_count[i] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_subcat_count(\n",
    "         hist_subcat_0,\n",
    "         hist_subcat_1,\n",
    "         hist_subcat_2,\n",
    "         hist_subcat_3,\n",
    "         hist_subcat_4,\n",
    "         hist_subcat_5,\n",
    "         hist_subcat_6,\n",
    "         hist_subcat_7,\n",
    "         hist_subcat_8,\n",
    "         hist_subcat_9,\n",
    "         impr_subcat,\n",
    "         impr_subcat_count,\n",
    "         k):\n",
    "\n",
    "    # Loop iterates over each row containing the listed categories\n",
    "    for i, temp in enumerate(zip(\n",
    "                                 hist_subcat_0,\n",
    "                                 hist_subcat_1,\n",
    "                                 hist_subcat_2,\n",
    "                                 hist_subcat_3,\n",
    "                                 hist_subcat_4,\n",
    "                                 hist_subcat_5,\n",
    "                                 hist_subcat_6,\n",
    "                                 hist_subcat_7,\n",
    "                                 hist_subcat_8,\n",
    "                                 hist_subcat_9,\n",
    "                                 impr_subcat,\n",
    "                                )):\n",
    "\n",
    "        # Counting the number of history sub-categories that matches with impression sub-category\n",
    "        for j in temp[:-1]:\n",
    "            if j == temp[-1]:\n",
    "                k += 1\n",
    "        # Update the impression sub-category count in corresponding row\n",
    "        impr_subcat_count[i] = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inheriting from NVTabular Operator class to add count encoding to dataset\n",
    "class create_count_features(Operator):\n",
    "    def transform(self, columns, gdf):\n",
    "        if columns[-1] == 'impr_cat':\n",
    "            gdf = gdf.apply_rows(add_cat_count,incols = ['hist_cat_{}'.format(i) for i in range(max_hist)]+['impr_cat'],outcols = {'impr_cat_count': np.int64},kwargs={'k': 0})\n",
    "            return(gdf.drop(columns,axis=1))\n",
    "        if columns[-1] == 'impr_subcat':\n",
    "            gdf = gdf.apply_rows(add_subcat_count,incols = ['hist_subcat_{}'.format(i) for i in range(max_hist)]+['impr_subcat'],outcols = {'impr_subcat_count': np.int64},kwargs={'k': 0})\n",
    "            return(gdf.drop(columns,axis=1))\n",
    "\n",
    "    def output_column_names(self, columns):\n",
    "        col = []\n",
    "        if columns[-1] == 'impr_cat':\n",
    "            col.append('impr_cat_count')\n",
    "        if columns[-1] == 'impr_subcat':\n",
    "            col.append('impr_subcat_count')\n",
    "        return col\n",
    "\n",
    "    def dependencies(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create target encoding based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_columns = [['hist_cat_'+str(j) for j in range(i-5+1, i+1)] + ['impr_cat'] for i in range(4, max_hist)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_encode = (\n",
    "    te_columns >>\n",
    "    nvt.ops.TargetEncoding(\n",
    "        ['label'],\n",
    "        out_path = BASE_DIR,\n",
    "        kfold=5,\n",
    "        p_smooth=20,\n",
    "        out_dtype=\"float32\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime = nvt.ColumnGroup(['time']) >> (lambda col: cudf.to_datetime(col,format=\"%m/%d/%Y %I:%M:%S %p\"))\n",
    "\n",
    "hour = datetime >> (lambda col: col.dt.hour) >> nvt.ops.Rename(postfix = '_hour')\n",
    "minute = datetime >> (lambda col: col.dt.minute) >> nvt.ops.Rename(postfix = '_minute')\n",
    "seconds = datetime >> (lambda col: col.dt.second) >> nvt.ops.Rename(postfix = '_second')\n",
    "\n",
    "weekday = datetime >> (lambda col: col.dt.weekday) >> nvt.ops.Rename(postfix = '_wd')\n",
    "day = datetime >> (lambda col: cudf.to_datetime(col, unit='s').dt.day) >> nvt.ops.Rename(postfix = '_day')\n",
    "\n",
    "week = day >> (lambda col: (col/7).floor().astype('int')) >> nvt.ops.Rename(postfix = '_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count_encode = ['hist_cat_{}'.format(i) for i in range(max_hist)] + ['impr_cat'] >> create_count_features()\n",
    "\n",
    "subcat_count_encode = ['hist_subcat_{}'.format(i) for i in range(max_hist)] + ['impr_subcat'] >> create_count_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = cat_features + datetime + hour + minute + seconds + weekday + day + week >> nvt.ops.Categorify(out_path = data_output_path)\n",
    "cont_features = cont_features + cat_count_encode + subcat_count_encode >> nvt.ops.FillMissing() >> nvt.ops.NormalizeMinMax()\n",
    "cont_features += target_encode >> nvt.ops.Rename(postfix = '_TE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"3638pt\" height=\"692pt\"\n",
       " viewBox=\"0.00 0.00 3638.04 692.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 688)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-688 3634.04,-688 3634.04,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1831.09\" cy=\"-162\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1831.09\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node22\" class=\"node\">\n",
       "<title>16</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1175.09\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1175.09\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;16 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>0&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1785.49,-156.13C1662.2,-142.98 1324.04,-106.89 1211.82,-94.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1212,-91.42 1201.69,-93.84 1211.26,-98.38 1212,-91.42\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2323.09\" cy=\"-234\" rx=\"84.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2323.09\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">TargetEncoding</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>1&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2254.94,-223.3C2156.25,-209.26 1975.51,-183.55 1885.31,-170.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1885.68,-167.23 1875.29,-169.29 1884.7,-174.16 1885.68,-167.23\"/>\n",
       "</g>\n",
       "<!-- 21 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>21</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"2323.09\" cy=\"-306\" rx=\"1102.9\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"2323.09\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[(&#39;hist_cat_0&#39;, &#39;hist_cat_1&#39;, &#39;hist_cat_2&#39;, &#39;hist_cat_3&#39;, &#39;hist_cat_4&#39;, &#39;impr_cat&#39;), (&#39;hist_cat_1&#39;, &#39;hist_cat_2&#39;, &#39;hist_cat_3&#39;, &#39;hist_cat_4&#39;, &#39;hist_cat_5&#39;, &#39;impr_cat&#39;), (&#39;hist_cat_2&#39;, &#39;hist_cat_3&#39;, &#39;hist_cat_4&#39;, &#39;hist_cat_5&#39;, &#39;hist_cat_6&#39;, &#39;impr_cat&#39;)...]</text>\n",
       "</g>\n",
       "<!-- 21&#45;&gt;1 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>21&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M2323.09,-287.7C2323.09,-279.98 2323.09,-270.71 2323.09,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2326.59,-262.1 2323.09,-252.1 2319.59,-262.1 2326.59,-262.1\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>18</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"3537.09\" cy=\"-306\" rx=\"92.88\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"3537.09\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[label]</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;1 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>18&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M3472.23,-293.02C3459.93,-291.08 3447.14,-289.29 3435.09,-288 3059.61,-247.9 2609.55,-238.14 2417.46,-235.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"2417.44,-232.26 2407.4,-235.64 2417.36,-239.26 2417.44,-232.26\"/>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"61.09\" cy=\"-522\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"61.09\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"152.09\" cy=\"-450\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"152.09\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;10 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>2&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M82.2,-504.76C94.64,-495.2 110.52,-482.98 124.01,-472.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"126.25,-475.3 132.04,-466.43 121.98,-469.75 126.25,-475.3\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"411.09\" cy=\"-594\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"411.09\" y=\"-590.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>7&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M359.84,-584.11C303.58,-574.16 210.65,-557.18 131.09,-540 126.18,-538.94 121.08,-537.79 115.98,-536.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"116.74,-533.19 106.2,-534.31 115.14,-540.01 116.74,-533.19\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>13</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"201.09\" cy=\"-522\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"201.09\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;13 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>7&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M372.09,-580C337.46,-568.46 286.74,-551.55 249.52,-539.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"250.49,-535.77 239.89,-535.93 248.27,-542.42 250.49,-535.77\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"341.09\" cy=\"-522\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"341.09\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;4 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>7&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M394.51,-576.41C385.61,-567.52 374.51,-556.41 364.73,-546.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"367.11,-544.07 357.56,-539.47 362.16,-549.02 367.11,-544.07\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"481.09\" cy=\"-522\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"481.09\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;8 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>7&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M427.68,-576.41C436.58,-567.52 447.68,-556.41 457.46,-546.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"460.03,-549.02 464.62,-539.47 455.08,-544.07 460.03,-549.02\"/>\n",
       "</g>\n",
       "<!-- 28 -->\n",
       "<g id=\"node25\" class=\"node\">\n",
       "<title>28</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"507.09\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"507.09\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;28 -->\n",
       "<g id=\"edge28\" class=\"edge\">\n",
       "<title>7&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M464.84,-585.43C494.42,-578.49 529.42,-565.24 551.09,-540 577.45,-509.32 570.09,-491.45 570.09,-451 570.09,-451 570.09,-451 570.09,-377 570.09,-332.17 543.54,-285.7 524.91,-258.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"527.58,-256.33 518.94,-250.2 521.87,-260.38 527.58,-256.33\"/>\n",
       "</g>\n",
       "<!-- 23 -->\n",
       "<g id=\"node28\" class=\"node\">\n",
       "<title>23</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"659.09\" cy=\"-522\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"659.09\" y=\"-518.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;23 -->\n",
       "<g id=\"edge22\" class=\"edge\">\n",
       "<title>7&#45;&gt;23</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M453.73,-580.97C496.18,-568.99 561.4,-550.57 606.92,-537.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"607.93,-541.08 616.6,-534.99 606.03,-534.34 607.93,-541.08\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"317.09\" cy=\"-378\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"317.09\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;28 -->\n",
       "<g id=\"edge32\" class=\"edge\">\n",
       "<title>3&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M337.79,-361.53C372.84,-335.34 443.77,-282.33 481.75,-253.94\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"483.85,-256.74 489.77,-247.95 479.66,-251.13 483.85,-256.74\"/>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;3 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>13&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M214.63,-504.43C234.97,-479.53 273.56,-432.3 297.14,-403.43\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"300.03,-405.42 303.65,-395.46 294.61,-400.99 300.03,-405.42\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"431.09\" cy=\"-378\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"431.09\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;5 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>4&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M351.77,-504.15C367.4,-479.49 396.63,-433.37 414.91,-404.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"418.03,-406.15 420.43,-395.82 412.12,-402.4 418.03,-406.15\"/>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;28 -->\n",
       "<g id=\"edge30\" class=\"edge\">\n",
       "<title>5&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M440.11,-360.15C453.32,-335.47 478.04,-289.28 493.48,-260.44\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"496.69,-261.85 498.32,-251.39 490.52,-258.55 496.69,-261.85\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"487.09\" cy=\"-450\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"487.09\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;28 -->\n",
       "<g id=\"edge33\" class=\"edge\">\n",
       "<title>6&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M488.7,-431.85C492.16,-394.83 500.35,-307.18 504.54,-262.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"508.04,-262.51 505.48,-252.23 501.07,-261.86 508.04,-262.51\"/>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;6 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>8&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M482.58,-503.7C483.24,-495.98 484.03,-486.71 484.77,-478.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"488.26,-478.37 485.63,-468.1 481.29,-477.77 488.26,-478.37\"/>\n",
       "</g>\n",
       "<!-- 29 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>29</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"411.09\" cy=\"-666\" rx=\"91.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"411.09\" y=\"-662.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[time]</text>\n",
       "</g>\n",
       "<!-- 29&#45;&gt;7 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>29&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M411.09,-647.7C411.09,-639.98 411.09,-630.71 411.09,-622.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"414.59,-622.1 411.09,-612.1 407.59,-622.1 414.59,-622.1\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"926.09\" cy=\"-378\" rx=\"118.08\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"926.09\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[hist_count]</text>\n",
       "</g>\n",
       "<!-- 27 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>27</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1175.09\" cy=\"-306\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1175.09\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;27 -->\n",
       "<g id=\"edge26\" class=\"edge\">\n",
       "<title>9&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M995.7,-363.32C1037.82,-354.15 1092.25,-340.7 1139.09,-324 1141,-323.32 1142.94,-322.58 1144.88,-321.79\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1146.69,-324.81 1154.45,-317.6 1143.88,-318.4 1146.69,-324.81\"/>\n",
       "</g>\n",
       "<!-- 25 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>25</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"152.09\" cy=\"-378\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"152.09\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;25 -->\n",
       "<g id=\"edge24\" class=\"edge\">\n",
       "<title>10&#45;&gt;25</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M152.09,-431.7C152.09,-423.98 152.09,-414.71 152.09,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"155.59,-406.1 152.09,-396.1 148.59,-406.1 155.59,-406.1\"/>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;28 -->\n",
       "<g id=\"edge34\" class=\"edge\">\n",
       "<title>10&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M173.39,-433.82C187.51,-423.53 206.28,-409.41 222.09,-396 239.84,-380.96 241.42,-373.87 260.09,-360 311.88,-321.55 328.47,-316.98 386.09,-288 415.63,-273.15 450.26,-258.22 474.89,-248.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"476.55,-251.11 484.46,-244.07 473.88,-244.64 476.55,-251.11\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1061.09\" cy=\"-450\" rx=\"230.16\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1061.09\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[hist_cat_0, hist_cat_1, hist_cat_2...]</text>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node26\" class=\"node\">\n",
       "<title>19</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1175.09\" cy=\"-378\" rx=\"113.18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1175.09\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">create_count_features</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;19 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>11&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1088.69,-432.05C1103.93,-422.7 1123.02,-410.98 1139.38,-400.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1141.46,-403.76 1148.15,-395.55 1137.79,-397.8 1141.46,-403.76\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>12</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1589.09\" cy=\"-450\" rx=\"280.25\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1589.09\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[hist_subcat_0, hist_subcat_1, hist_subcat_2...]</text>\n",
       "</g>\n",
       "<!-- 24 -->\n",
       "<g id=\"node29\" class=\"node\">\n",
       "<title>24</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1504.09\" cy=\"-378\" rx=\"113.18\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1504.09\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">create_count_features</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;24 -->\n",
       "<g id=\"edge23\" class=\"edge\">\n",
       "<title>12&#45;&gt;24</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1568.08,-431.7C1557.3,-422.81 1544.01,-411.87 1532.34,-402.26\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1534.52,-399.52 1524.57,-395.86 1530.07,-404.92 1534.52,-399.52\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>14</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1175.09\" cy=\"-234\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1175.09\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node24\" class=\"node\">\n",
       "<title>20</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1175.09\" cy=\"-162\" rx=\"96.68\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1175.09\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">NormalizeMinMax</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>14&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1175.09,-215.7C1175.09,-207.98 1175.09,-198.71 1175.09,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1178.59,-190.1 1175.09,-180.1 1171.59,-190.1 1178.59,-190.1\"/>\n",
       "</g>\n",
       "<!-- 27&#45;&gt;14 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>27&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1175.09,-287.7C1175.09,-279.98 1175.09,-270.71 1175.09,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1178.59,-262.1 1175.09,-252.1 1171.59,-262.1 1178.59,-262.1\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>15</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"159.09\" cy=\"-306\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"159.09\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;28 -->\n",
       "<g id=\"edge35\" class=\"edge\">\n",
       "<title>15&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M197.48,-294.99C207.12,-292.59 217.47,-290.11 227.09,-288 314.3,-268.86 417.71,-250.37 471.13,-241.12\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"471.87,-244.54 481.13,-239.4 470.68,-237.65 471.87,-244.54\"/>\n",
       "</g>\n",
       "<!-- 25&#45;&gt;15 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>25&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M153.82,-359.7C154.6,-351.98 155.52,-342.71 156.38,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"159.87,-334.4 157.38,-324.1 152.91,-333.71 159.87,-334.4\"/>\n",
       "</g>\n",
       "<!-- 30 -->\n",
       "<g id=\"node31\" class=\"node\">\n",
       "<title>30</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1175.09\" cy=\"-18\" rx=\"227.46\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1175.09\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">output cols=[time, hist_cat_0, hist_subcat_0...]</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;30 -->\n",
       "<g id=\"edge36\" class=\"edge\">\n",
       "<title>16&#45;&gt;30</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1175.09,-71.7C1175.09,-63.98 1175.09,-54.71 1175.09,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1178.59,-46.1 1175.09,-36.1 1171.59,-46.1 1178.59,-46.1\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node23\" class=\"node\">\n",
       "<title>17</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"754.09\" cy=\"-162\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"754.09\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;16 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>17&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M805.3,-152.49C891.73,-138.11 1064.47,-109.39 1139.23,-96.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1139.82,-100.41 1149.11,-95.32 1138.68,-93.51 1139.82,-100.41\"/>\n",
       "</g>\n",
       "<!-- 20&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>20&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1175.09,-143.7C1175.09,-135.98 1175.09,-126.71 1175.09,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1178.59,-118.1 1175.09,-108.1 1171.59,-118.1 1178.59,-118.1\"/>\n",
       "</g>\n",
       "<!-- 28&#45;&gt;17 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>28&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M531.68,-226.03C571.23,-214.82 649.83,-192.55 702.2,-177.71\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"703.31,-181.03 711.98,-174.94 701.4,-174.29 703.31,-181.03\"/>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;27 -->\n",
       "<g id=\"edge25\" class=\"edge\">\n",
       "<title>19&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1175.09,-359.7C1175.09,-351.98 1175.09,-342.71 1175.09,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1178.59,-334.1 1175.09,-324.1 1171.59,-334.1 1178.59,-334.1\"/>\n",
       "</g>\n",
       "<!-- 22 -->\n",
       "<g id=\"node27\" class=\"node\">\n",
       "<title>22</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"652.09\" cy=\"-450\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"652.09\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 22&#45;&gt;28 -->\n",
       "<g id=\"edge31\" class=\"edge\">\n",
       "<title>22&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M648.25,-431.82C640.54,-400.43 620.71,-332.92 584.09,-288 571.41,-272.44 553,-259.54 537.37,-250.36\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"538.97,-247.25 528.54,-245.4 535.54,-253.35 538.97,-247.25\"/>\n",
       "</g>\n",
       "<!-- 23&#45;&gt;22 -->\n",
       "<g id=\"edge21\" class=\"edge\">\n",
       "<title>23&#45;&gt;22</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M657.36,-503.7C656.59,-495.98 655.67,-486.71 654.81,-478.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"658.28,-477.71 653.81,-468.1 651.32,-478.4 658.28,-477.71\"/>\n",
       "</g>\n",
       "<!-- 24&#45;&gt;27 -->\n",
       "<g id=\"edge27\" class=\"edge\">\n",
       "<title>24&#45;&gt;27</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1414.47,-366.99C1355.69,-358.92 1277.68,-345.33 1211.09,-324 1209.17,-323.38 1207.21,-322.69 1205.26,-321.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1206.23,-318.54 1195.66,-317.84 1203.49,-324.98 1206.23,-318.54\"/>\n",
       "</g>\n",
       "<!-- 26 -->\n",
       "<g id=\"node30\" class=\"node\">\n",
       "<title>26</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"883.09\" cy=\"-306\" rx=\"246.96\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"883.09\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[hist_cat_0, hist_subcat_0, hist_cat_1...]</text>\n",
       "</g>\n",
       "<!-- 26&#45;&gt;28 -->\n",
       "<g id=\"edge29\" class=\"edge\">\n",
       "<title>26&#45;&gt;28</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M797.3,-289.03C717.11,-274.1 601.28,-252.53 543.19,-241.72\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"543.51,-238.22 533.03,-239.83 542.22,-245.1 543.51,-238.22\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7d60e52c10a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = cat_features + cont_features\n",
    "output.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = nvt.Workflow(cat_features + cont_features + labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = nvt.Dataset(os.path.join(data_input_path, \"train.parquet\"), engine=\"parquet\",part_size=\"256MB\")\n",
    "data_valid = nvt.Dataset(os.path.join(data_input_path, \"valid.parquet\"), engine=\"parquet\",part_size=\"256MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dtypes={}\n",
    "\n",
    "for col in cat_features.columns:\n",
    "    dict_dtypes[col] = np.int64\n",
    "\n",
    "for col in cont_features.columns:\n",
    "    dict_dtypes[col] = np.float32\n",
    "\n",
    "for col in labels:\n",
    "    dict_dtypes[col] = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 38s, sys: 1min 36s, total: 7min 14s\n",
      "Wall time: 7min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "proc.fit(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57min 59s, sys: 12min 37s, total: 1h 10min 36s\n",
      "Wall time: 1h 10min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# For training set\n",
    "proc.transform(data_train).to_parquet(output_path=output_train_path,\n",
    "                                shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                dtypes=dict_dtypes,\n",
    "                                out_files_per_proc=10,\n",
    "                                cats = cat_features.columns,\n",
    "                                conts = cont_features.columns,\n",
    "                                labels = labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 53s, sys: 2min 8s, total: 12min 2s\n",
      "Wall time: 11min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# For validation set\n",
    "proc.transform(data_valid).to_parquet(output_path=output_valid_path,\n",
    "                                shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                dtypes=dict_dtypes,\n",
    "                                out_files_per_proc=10,\n",
    "                                cats = cat_features.columns,\n",
    "                                conts = cont_features.columns,\n",
    "                                labels = labels)\n",
    "rmm.reinitialize(managed_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_stats': [{'file_name': '0.6b641595fcc742e3aa2758ccf3b12205.parquet',\n",
       "   'num_rows': 7715947},\n",
       "  {'file_name': '1.88063cff803b42509f06f272d74291d0.parquet',\n",
       "   'num_rows': 7720030},\n",
       "  {'file_name': '2.40ecd7d27df24705b0627b504ebc8616.parquet',\n",
       "   'num_rows': 7715550},\n",
       "  {'file_name': '3.c0c7e9a00f484e8193ea3c0f25f08965.parquet',\n",
       "   'num_rows': 7714724},\n",
       "  {'file_name': '4.4ea79a5b40b64ff681fce570749e6041.parquet',\n",
       "   'num_rows': 7720890},\n",
       "  {'file_name': '5.de5a10a5b2a54778bc733eac289cf592.parquet',\n",
       "   'num_rows': 7715209},\n",
       "  {'file_name': '6.85b83a311c584778a40987115a3c80c5.parquet',\n",
       "   'num_rows': 7718409},\n",
       "  {'file_name': '7.3eaae381ad9e497ab615fd9f927702ab.parquet',\n",
       "   'num_rows': 7721110},\n",
       "  {'file_name': '8.b2dabad9e730424d8c21f13591dc99b8.parquet',\n",
       "   'num_rows': 7715087},\n",
       "  {'file_name': '9.2b1125b0e9be4b6f9c6d387d688df406.parquet',\n",
       "   'num_rows': 7718471}],\n",
       " 'cats': [{'col_name': 'time', 'index': 0},\n",
       "  {'col_name': 'hist_cat_0', 'index': 1},\n",
       "  {'col_name': 'hist_subcat_0', 'index': 2},\n",
       "  {'col_name': 'hist_cat_1', 'index': 3},\n",
       "  {'col_name': 'hist_subcat_1', 'index': 4},\n",
       "  {'col_name': 'hist_cat_2', 'index': 5},\n",
       "  {'col_name': 'hist_subcat_2', 'index': 6},\n",
       "  {'col_name': 'hist_cat_3', 'index': 7},\n",
       "  {'col_name': 'hist_subcat_3', 'index': 8},\n",
       "  {'col_name': 'hist_cat_4', 'index': 9},\n",
       "  {'col_name': 'hist_subcat_4', 'index': 10},\n",
       "  {'col_name': 'hist_cat_5', 'index': 11},\n",
       "  {'col_name': 'hist_subcat_5', 'index': 12},\n",
       "  {'col_name': 'hist_cat_6', 'index': 13},\n",
       "  {'col_name': 'hist_subcat_6', 'index': 14},\n",
       "  {'col_name': 'hist_cat_7', 'index': 15},\n",
       "  {'col_name': 'hist_subcat_7', 'index': 16},\n",
       "  {'col_name': 'hist_cat_8', 'index': 17},\n",
       "  {'col_name': 'hist_subcat_8', 'index': 18},\n",
       "  {'col_name': 'hist_cat_9', 'index': 19},\n",
       "  {'col_name': 'hist_subcat_9', 'index': 20},\n",
       "  {'col_name': 'impr_cat', 'index': 21},\n",
       "  {'col_name': 'impr_subcat', 'index': 22},\n",
       "  {'col_name': 'impression_id', 'index': 23},\n",
       "  {'col_name': 'uid', 'index': 24},\n",
       "  {'col_name': 'time_hour', 'index': 25},\n",
       "  {'col_name': 'time_minute', 'index': 26},\n",
       "  {'col_name': 'time_second', 'index': 27},\n",
       "  {'col_name': 'time_wd', 'index': 28},\n",
       "  {'col_name': 'time_day', 'index': 29},\n",
       "  {'col_name': 'time_day_week', 'index': 30}],\n",
       " 'conts': [{'col_name': 'impr_cat_count', 'index': 31},\n",
       "  {'col_name': 'hist_count', 'index': 32},\n",
       "  {'col_name': 'impr_subcat_count', 'index': 33},\n",
       "  {'col_name': 'TE_hist_cat_0_hist_cat_1_hist_cat_2_hist_cat_3_hist_cat_4_impr_cat_label_TE',\n",
       "   'index': 34},\n",
       "  {'col_name': 'TE_hist_cat_1_hist_cat_2_hist_cat_3_hist_cat_4_hist_cat_5_impr_cat_label_TE',\n",
       "   'index': 35},\n",
       "  {'col_name': 'TE_hist_cat_2_hist_cat_3_hist_cat_4_hist_cat_5_hist_cat_6_impr_cat_label_TE',\n",
       "   'index': 36},\n",
       "  {'col_name': 'TE_hist_cat_3_hist_cat_4_hist_cat_5_hist_cat_6_hist_cat_7_impr_cat_label_TE',\n",
       "   'index': 37},\n",
       "  {'col_name': 'TE_hist_cat_4_hist_cat_5_hist_cat_6_hist_cat_7_hist_cat_8_impr_cat_label_TE',\n",
       "   'index': 38},\n",
       "  {'col_name': 'TE_hist_cat_5_hist_cat_6_hist_cat_7_hist_cat_8_hist_cat_9_impr_cat_label_TE',\n",
       "   'index': 39}],\n",
       " 'labels': [{'col_name': 'label', 'index': 40}]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(os.path.join(output_train_path, '_metadata.json'),'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hist_cat_0': (18, 16),\n",
       " 'hist_cat_1': (18, 16),\n",
       " 'hist_cat_2': (19, 16),\n",
       " 'hist_cat_3': (18, 16),\n",
       " 'hist_cat_4': (18, 16),\n",
       " 'hist_cat_5': (18, 16),\n",
       " 'hist_cat_6': (18, 16),\n",
       " 'hist_cat_7': (18, 16),\n",
       " 'hist_cat_8': (17, 16),\n",
       " 'hist_cat_9': (17, 16),\n",
       " 'hist_subcat_0': (235, 34),\n",
       " 'hist_subcat_1': (239, 34),\n",
       " 'hist_subcat_2': (236, 34),\n",
       " 'hist_subcat_3': (235, 34),\n",
       " 'hist_subcat_4': (229, 34),\n",
       " 'hist_subcat_5': (224, 33),\n",
       " 'hist_subcat_6': (225, 33),\n",
       " 'hist_subcat_7': (219, 33),\n",
       " 'hist_subcat_8': (213, 32),\n",
       " 'hist_subcat_9': (199, 31),\n",
       " 'impr_cat': (26708, 482),\n",
       " 'impr_subcat': (26708, 482),\n",
       " 'impression_id': (2232749, 512),\n",
       " 'time': (90397, 512),\n",
       " 'time_day': (7, 16),\n",
       " 'time_day_week': (3, 16),\n",
       " 'time_hour': (16, 16),\n",
       " 'time_minute': (61, 16),\n",
       " 'time_second': (61, 16),\n",
       " 'time_wd': (6, 16),\n",
       " 'uid': (711223, 512)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nvtabular.ops import get_embedding_sizes\n",
    "embeddings_count_encode =  get_embedding_sizes(proc)\n",
    "embeddings_count_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[90397,\n",
       " 18,\n",
       " 235,\n",
       " 18,\n",
       " 239,\n",
       " 19,\n",
       " 236,\n",
       " 18,\n",
       " 235,\n",
       " 18,\n",
       " 229,\n",
       " 18,\n",
       " 224,\n",
       " 18,\n",
       " 225,\n",
       " 18,\n",
       " 219,\n",
       " 17,\n",
       " 213,\n",
       " 17,\n",
       " 199,\n",
       " 26708,\n",
       " 26708,\n",
       " 2232749,\n",
       " 711223,\n",
       " 16,\n",
       " 61,\n",
       " 61,\n",
       " 6,\n",
       " 7,\n",
       " 3]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reformatting the above output for ease of copy paste in HugeCTRs config.json\n",
    "\n",
    "embedding_size_str_count_encode = [embeddings_count_encode[x][0] for x in cat_features.columns]\n",
    "embedding_size_str_count_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have 2 versions of our dataset ready, one with time based features and other with count + target encoded features, we can start training a few DNNs using HugeCTR."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training DLRM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python low level train API requires a train config.json with the arguments and definitions of various training parameters like - optimizer, iterations, neural architecture and dataset.<br>\n",
    "As a first step, we will develop this config file for our feature engineered dataset and DLRM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths to save the config and the weights\n",
    "\n",
    "config_file_path = os.path.join(config_output_path,'dlrm_fp32_simple-time_1gpu.json')\n",
    "weights_output_path = os.path.join(weights_path,'dlrm_fp32_simple-time_1gpu/')\n",
    "\n",
    "# Creating Directory inside weights folder\n",
    "if os.path.isdir(weights_output_path):\n",
    "    shutil.rmtree(weights_output_path)\n",
    "os.mkdir(weights_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first, we'll train on time based feature version of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the simple time based feature processed dataset\n",
    "output_train_path = os.path.join(BASE_DIR, \"processed_nvt/train\")\n",
    "output_valid_path = os.path.join(BASE_DIR, \"processed_nvt/valid\")\n",
    "\n",
    "# Model related parameter\n",
    "embedding_vec_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture and training configuration\n",
    "\n",
    "optimizer = {\n",
    "        \"type\": \"Adam\",\n",
    "        \"update_type\": \"Local\",\n",
    "        \"adam_hparam\": {\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"beta1\": 0.9,\n",
    "            \"beta2\": 0.999,\n",
    "            \"epsilon\": 1e-07,\n",
    "            \"warmup_steps\": 10000,\n",
    "            \"decay_start\": 20000,\n",
    "            \"decay_steps\": 200000,\n",
    "            \"decay_power\": 1,\n",
    "            \"end_lr\": 0.000001\n",
    "        }\n",
    "    }\n",
    "\n",
    "layers = [\n",
    "        {\n",
    "            \"name\": \"data\",\n",
    "            \"type\": \"Data\",\n",
    "            \"format\": \"Parquet\",\n",
    "            \"slot_size_array\": embedding_size_str_simple_time,\n",
    "            \"source\": output_train_path+\"/_file_list.txt\",\n",
    "            \"eval_source\": output_valid_path+\"/_file_list.txt\",\n",
    "            \"check\": \"None\",\n",
    "            \"label\": {\n",
    "                \"top\": \"label\",\n",
    "                \"label_dim\": 1\n",
    "            },\n",
    "            \"dense\": {\n",
    "                \"top\": \"dense\",\n",
    "                \"dense_dim\": 1\n",
    "            },\n",
    "            \"sparse\": [\n",
    "                {\n",
    "                    \"top\": \"data1\",\n",
    "                    \"type\": \"LocalizedSlot\",\n",
    "                    \"max_feature_num_per_sample\": len(embeddings_simple_time),\n",
    "                    \"max_nnz\": 1,\n",
    "                    \"slot_num\": len(embeddings_simple_time)\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"sparse_embedding1\",\n",
    "            \"type\": \"LocalizedSlotSparseEmbeddingHash\",\n",
    "            \"bottom\": \"data1\",\n",
    "            \"top\": \"sparse_embedding1\",\n",
    "            \"sparse_embedding_hparam\": {\n",
    "                \"slot_size_array\": embedding_size_str_simple_time,\n",
    "                \"embedding_vec_size\": embedding_vec_size,\n",
    "                \"combiner\": 0\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc1\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"dense\",\n",
    "            \"top\": \"fc1\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 512\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu1\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc1\",\n",
    "            \"top\": \"relu1\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc2\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"relu1\",\n",
    "            \"top\": \"fc2\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 256\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu2\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc2\",\n",
    "            \"top\": \"relu2\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc3\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"relu2\",\n",
    "            \"top\": \"fc3\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": embedding_vec_size\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu3\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc3\",\n",
    "            \"top\": \"relu3\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"interaction1\",\n",
    "            \"type\": \"Interaction\",\n",
    "            \"bottom\": [\n",
    "                \"relu3\",\n",
    "                \"sparse_embedding1\"\n",
    "            ],\n",
    "            \"top\": \"interaction1\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc4\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"interaction1\",\n",
    "            \"top\": \"fc4\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 1024\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu4\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc4\",\n",
    "            \"top\": \"relu4\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc5\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"relu4\",\n",
    "            \"top\": \"fc5\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 1024\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu5\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc5\",\n",
    "            \"top\": \"relu5\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc6\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"relu5\",\n",
    "            \"top\": \"fc6\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 512\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu6\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc6\",\n",
    "            \"top\": \"relu6\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc7\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"relu6\",\n",
    "            \"top\": \"fc7\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 256\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu7\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc7\",\n",
    "            \"top\": \"relu7\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc8\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"relu7\",\n",
    "            \"top\": \"fc8\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"loss\",\n",
    "            \"type\": \"BinaryCrossEntropyLoss\",\n",
    "            \"bottom\": [\n",
    "                \"fc8\",\n",
    "                \"label\"\n",
    "            ],\n",
    "            \"top\": \"loss\"\n",
    "        }\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"optimizer\": optimizer,\n",
    "    \"layers\": layers\n",
    "}\n",
    "\n",
    "with open(config_file_path,'w') as f:\n",
    "    json.dump(config,f,indent = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can start the training using the above config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HUGECTR][INFO] iter: 0; loss: 0.482908; lr: 0.000000[14d03h56m03s][HUGECTR][INFO]: Global seed is 3431791815\n",
      "\n",
      "[14d03h56m04s][HUGECTR][INFO]: Peer-to-peer access cannot be fully enabled.\n",
      "Device 0: NVIDIA A100-SXM4-40GB\n",
      "[14d03h56m04s][HUGECTR][INFO]: cache_eval_data is not specified using default: 0\n",
      "[14d03h56m04s][HUGECTR][INFO]: num_workers is not specified using default: 1\n",
      "[14d03h56m04s][HUGECTR][INFO]: num of DataReader workers: 1\n",
      "[14d03h56m04s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[14d03h56m04s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[14d03h56m04s][HUGECTR][INFO]: Vocabulary size: 3090372\n",
      "[14d03h56m04s][HUGECTR][INFO]: max_vocabulary_size_per_gpu_=3090372\n",
      "[14d03h56m04s][HUGECTR][INFO]: All2All Warmup Start\n",
      "[14d03h56m04s][HUGECTR][INFO]: All2All Warmup End\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot0 , slot_size=16, key_offset=0, value_index_offset=0\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot1 , slot_size=18, key_offset=16, value_index_offset=16\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot2 , slot_size=235, key_offset=34, value_index_offset=34\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot3 , slot_size=18, key_offset=269, value_index_offset=269\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot4 , slot_size=239, key_offset=287, value_index_offset=287\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot5 , slot_size=19, key_offset=526, value_index_offset=526\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot6 , slot_size=236, key_offset=545, value_index_offset=545\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot7 , slot_size=18, key_offset=781, value_index_offset=781\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot8 , slot_size=235, key_offset=799, value_index_offset=799\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot9 , slot_size=18, key_offset=1034, value_index_offset=1034\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot10 , slot_size=229, key_offset=1052, value_index_offset=1052\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot11 , slot_size=18, key_offset=1281, value_index_offset=1281\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot12 , slot_size=224, key_offset=1299, value_index_offset=1299\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot13 , slot_size=18, key_offset=1523, value_index_offset=1523\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot14 , slot_size=225, key_offset=1541, value_index_offset=1541\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot15 , slot_size=18, key_offset=1766, value_index_offset=1766\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot16 , slot_size=219, key_offset=1784, value_index_offset=1784\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot17 , slot_size=17, key_offset=2003, value_index_offset=2003\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot18 , slot_size=213, key_offset=2020, value_index_offset=2020\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot19 , slot_size=17, key_offset=2233, value_index_offset=2233\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot20 , slot_size=199, key_offset=2250, value_index_offset=2250\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot21 , slot_size=26708, key_offset=2449, value_index_offset=2449\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot22 , slot_size=26708, key_offset=29157, value_index_offset=29157\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot23 , slot_size=2232749, key_offset=55865, value_index_offset=55865\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot24 , slot_size=711223, key_offset=2288614, value_index_offset=2288614\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot25 , slot_size=61, key_offset=2999837, value_index_offset=2999837\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot26 , slot_size=61, key_offset=2999898, value_index_offset=2999898\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot27 , slot_size=6, key_offset=2999959, value_index_offset=2999959\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot28 , slot_size=7, key_offset=2999965, value_index_offset=2999965\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot29 , slot_size=3, key_offset=2999972, value_index_offset=2999972\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot30 , slot_size=90397, key_offset=2999975, value_index_offset=2999975\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 init embedding done\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot0 , slot_size=16, key_offset=0, value_index_offset=0\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot1 , slot_size=18, key_offset=16, value_index_offset=16\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot2 , slot_size=235, key_offset=34, value_index_offset=34\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot3 , slot_size=18, key_offset=269, value_index_offset=269\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot4 , slot_size=239, key_offset=287, value_index_offset=287\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot5 , slot_size=19, key_offset=526, value_index_offset=526\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot6 , slot_size=236, key_offset=545, value_index_offset=545\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot7 , slot_size=18, key_offset=781, value_index_offset=781\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot8 , slot_size=235, key_offset=799, value_index_offset=799\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot9 , slot_size=18, key_offset=1034, value_index_offset=1034\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot10 , slot_size=229, key_offset=1052, value_index_offset=1052\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot11 , slot_size=18, key_offset=1281, value_index_offset=1281\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot12 , slot_size=224, key_offset=1299, value_index_offset=1299\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot13 , slot_size=18, key_offset=1523, value_index_offset=1523\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot14 , slot_size=225, key_offset=1541, value_index_offset=1541\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot15 , slot_size=18, key_offset=1766, value_index_offset=1766\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot16 , slot_size=219, key_offset=1784, value_index_offset=1784\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot17 , slot_size=17, key_offset=2003, value_index_offset=2003\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot18 , slot_size=213, key_offset=2020, value_index_offset=2020\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot19 , slot_size=17, key_offset=2233, value_index_offset=2233\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot20 , slot_size=199, key_offset=2250, value_index_offset=2250\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot21 , slot_size=26708, key_offset=2449, value_index_offset=2449\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot22 , slot_size=26708, key_offset=29157, value_index_offset=29157\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot23 , slot_size=2232749, key_offset=55865, value_index_offset=55865\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot24 , slot_size=711223, key_offset=2288614, value_index_offset=2288614\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot25 , slot_size=61, key_offset=2999837, value_index_offset=2999837\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot26 , slot_size=61, key_offset=2999898, value_index_offset=2999898\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot27 , slot_size=6, key_offset=2999959, value_index_offset=2999959\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot28 , slot_size=7, key_offset=2999965, value_index_offset=2999965\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot29 , slot_size=3, key_offset=2999972, value_index_offset=2999972\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot30 , slot_size=90397, key_offset=2999975, value_index_offset=2999975\n",
      "[14d03h56m04s][HUGECTR][INFO]: gpu0 init embedding done\n",
      "[HUGECTR][INFO] iter: 1000; loss: 0.183684; lr: 0.000100\n",
      "[HUGECTR][INFO] iter: 2000; loss: 0.175003; lr: 0.000200\n",
      "[HUGECTR][INFO] iter: 3000; loss: 0.146727; lr: 0.000300\n",
      "[HUGECTR][INFO] iter: 4000; loss: 0.159648; lr: 0.000400\n",
      "[HUGECTR][INFO] iter: 5000; loss: 0.143021; lr: 0.000500\n",
      "[HUGECTR][INFO] iter: 6000; loss: 0.155799; lr: 0.000600\n",
      "[HUGECTR][INFO] iter: 7000; loss: 0.155588; lr: 0.000700\n",
      "[HUGECTR][INFO] iter: 8000; loss: 0.144939; lr: 0.000800\n",
      "[HUGECTR][INFO] iter: 9000; loss: 0.156111; lr: 0.000900\n",
      "[HUGECTR][INFO] iter: 10000; loss: 0.152578; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 10000, [('AUC', 0.6082516312599182)]\n",
      "[14d03h56m40s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[14d03h56m41s][HUGECTR][INFO]: Rank0: Write hash table <key,slot_id,value> pairs to file\n",
      "[14d03h56m41s][HUGECTR][INFO]: Done\n",
      "[14d03h56m41s][HUGECTR][INFO]: Rank0: Write optimzer state to file\n",
      "[14d03h56m41s][HUGECTR][INFO]: Done\n",
      "[14d03h56m41s][HUGECTR][INFO]: Rank0: Write optimzer state to file\n",
      "[14d03h56m41s][HUGECTR][INFO]: Done\n",
      "[HUGECTR][INFO] iter: 11000; loss: 0.148627; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 12000; loss: 0.142269; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 13000; loss: 0.144158; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 14000; loss: 0.125636; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 15000; loss: 0.166003; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 16000; loss: 0.153128; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 17000; loss: 0.132572; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 18000; loss: 0.152138; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 19000; loss: 0.158920; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 20000; loss: 0.129274; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 20000, [('AUC', 0.6217789649963379)]\n",
      "[14d03h57m17s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[14d03h57m17s][HUGECTR][INFO]: Rank0: Write hash table <key,slot_id,value> pairs to file\n",
      "[14d03h57m17s][HUGECTR][INFO]: Done\n",
      "[14d03h57m17s][HUGECTR][INFO]: Rank0: Write optimzer state to file\n",
      "[14d03h57m17s][HUGECTR][INFO]: Done\n",
      "[14d03h57m17s][HUGECTR][INFO]: Rank0: Write optimzer state to file\n",
      "[14d03h57m17s][HUGECTR][INFO]: Done\n",
      "[HUGECTR][INFO] iter: 21000; loss: 0.162690; lr: 0.000995\n",
      "[HUGECTR][INFO] iter: 22000; loss: 0.153445; lr: 0.000990\n",
      "[HUGECTR][INFO] iter: 23000; loss: 0.149824; lr: 0.000985\n",
      "[HUGECTR][INFO] iter: 24000; loss: 0.153819; lr: 0.000980\n",
      "[HUGECTR][INFO] iter: 25000; loss: 0.149993; lr: 0.000975\n",
      "[HUGECTR][INFO] iter: 26000; loss: 0.152023; lr: 0.000970\n",
      "[HUGECTR][INFO] iter: 27000; loss: 0.156765; lr: 0.000965\n",
      "[HUGECTR][INFO] iter: 28000; loss: 0.139739; lr: 0.000960\n",
      "[HUGECTR][INFO] iter: 29000; loss: 0.156647; lr: 0.000955\n",
      "[HUGECTR][INFO] iter: 30000; loss: 0.141017; lr: 0.000950\n",
      "[HUGECTR][INFO] iter: 30000, [('AUC', 0.6590607166290283)]\n",
      "[14d03h57m53s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[14d03h57m53s][HUGECTR][INFO]: Rank0: Write hash table <key,slot_id,value> pairs to file\n",
      "[14d03h57m54s][HUGECTR][INFO]: Done\n",
      "[14d03h57m54s][HUGECTR][INFO]: Rank0: Write optimzer state to file\n",
      "[14d03h57m54s][HUGECTR][INFO]: Done\n",
      "[14d03h57m54s][HUGECTR][INFO]: Rank0: Write optimzer state to file\n",
      "[14d03h57m54s][HUGECTR][INFO]: Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from hugectr import Session, solver_parser_helper,get_learning_rate_scheduler\n",
    "from mpi4py import MPI\n",
    "\n",
    "# Solver related parameters\n",
    "NUM_GPUS = [0]                                                     \n",
    "json_file = config_file_path                                       \n",
    "batchsize = 2048                                                   \n",
    "batchsize_eval = 2048                                              \n",
    "max_eval_batches = 3768                                            \n",
    "\n",
    "# Training related parameters\n",
    "num_iter = 30001                                                   \n",
    "eval_trigger = 10000                                               \n",
    "snapshot_trigger = 10000                                           \n",
    "\n",
    "solver_config = solver_parser_helper(\n",
    "                                    seed = 0,\n",
    "                                    batchsize = batchsize,                   \n",
    "                                    batchsize_eval = batchsize_eval,         \n",
    "                                    max_eval_batches = max_eval_batches,     \n",
    "                                    model_file = \"\",                         \n",
    "                                    embedding_files = [],                    \n",
    "                                    vvgpu = [NUM_GPUS],                      \n",
    "                                    use_mixed_precision = False,             \n",
    "                                    scaler = 1024,                           \n",
    "                                    i64_input_key = True,                    \n",
    "                                    use_algorithm_search = False,            \n",
    "                                    use_cuda_graph = False,                  \n",
    "                                    repeat_dataset = True                    \n",
    "                                    )\n",
    "\n",
    "lr_sch = get_learning_rate_scheduler(json_file)                    \n",
    "\n",
    "sess = Session(solver_config, json_file)                           \n",
    "sess.start_data_reading()                                          \n",
    "\n",
    "for i in range(num_iter):                                          \n",
    "    lr = lr_sch.get_next()                                         \n",
    "    sess.set_learning_rate(lr)                                     \n",
    "    sess.train()                                                   \n",
    "\n",
    "    if (i%1000 == 0):\n",
    "        loss = sess.get_current_loss()                             \n",
    "        print(\"[HUGECTR][INFO] iter: {}; loss: {:.6f}; lr: {:.6f}\".format(i, loss, lr))\n",
    "    if (i%eval_trigger == 0 and i != 0):\n",
    "        sess.check_overflow()                                      \n",
    "        sess.copy_weights_for_evaluation()                         \n",
    "        for _ in range(solver_config.max_eval_batches):\n",
    "            sess.eval()                                            \n",
    "        metrics = sess.get_eval_metrics()                          \n",
    "        print(\"[HUGECTR][INFO] iter: {}, {}\".format(i, metrics))\n",
    "    if (i%snapshot_trigger == 0 and i != 0):\n",
    "        sess.download_params_to_files(weights_output_path , i)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the same methodology as done above, we will modify the DLRM config file for count + target encoded feature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to save the config and the weights\n",
    "\n",
    "config_file_path = os.path.join(config_output_path, 'dlrm_fp32_count-target-encode_1gpu.json')\n",
    "weights_output_path = os.path.join(weights_path,'dlrm_fp32_count-target-encode_1gpu/')\n",
    "\n",
    "# Creating Directory inside weights folder\n",
    "if os.path.isdir(weights_output_path):\n",
    "    shutil.rmtree(weights_output_path)\n",
    "os.mkdir(weights_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the simple time based feature processed dataset\n",
    "output_train_path = os.path.join(BASE_DIR, \"processed_ce-te/train\")\n",
    "output_valid_path = os.path.join(BASE_DIR, \"processed_ce-te/valid\")\n",
    "\n",
    "# Model related parameter\n",
    "embedding_vec_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = {\n",
    "        \"type\": \"Adam\",\n",
    "        \"update_type\": \"Local\",\n",
    "        \"adam_hparam\": {\n",
    "            \"learning_rate\": 0.001,\n",
    "            \"beta1\": 0.9,\n",
    "            \"beta2\": 0.999,\n",
    "            \"epsilon\": 1e-07,\n",
    "            \"warmup_steps\": 10000,\n",
    "            \"decay_start\": 20000,\n",
    "            \"decay_steps\": 200000,\n",
    "            \"decay_power\": 1,\n",
    "            \"end_lr\": 1e-06\n",
    "        }\n",
    "    }\n",
    "\n",
    "layers = [\n",
    "        {\n",
    "            \"name\": \"data\",\n",
    "            \"type\": \"Data\",\n",
    "            \"format\": \"Parquet\",\n",
    "            \"slot_size_array\": embedding_size_str_count_encode,\n",
    "            \"source\": output_train_path+\"/_file_list.txt\",\n",
    "            \"eval_source\": output_valid_path+\"/_file_list.txt\",\n",
    "            \"check\": \"None\",\n",
    "            \"label\": {\n",
    "                \"top\": \"label\",\n",
    "                \"label_dim\": 1\n",
    "            },\n",
    "            \"dense\": {\n",
    "                \"top\": \"dense\",\n",
    "                \"dense_dim\": 9\n",
    "            },\n",
    "            \"sparse\": [\n",
    "                {\n",
    "                    \"top\": \"data1\",\n",
    "                    \"type\": \"LocalizedSlot\",\n",
    "                    \"max_feature_num_per_sample\": len(embeddings_count_encode),\n",
    "                    \"max_nnz\": 1,\n",
    "                    \"slot_num\": len(embeddings_count_encode)\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"sparse_embedding1\",\n",
    "            \"type\": \"LocalizedSlotSparseEmbeddingHash\",\n",
    "            \"bottom\": \"data1\",\n",
    "            \"top\": \"sparse_embedding1\",\n",
    "            \"sparse_embedding_hparam\": {\n",
    "                \"slot_size_array\": embedding_size_str_count_encode,\n",
    "                \"embedding_vec_size\": embedding_vec_size,\n",
    "                \"combiner\": 0\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc1\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"dense\",\n",
    "            \"top\": \"fc1\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 512\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu1\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc1\",\n",
    "            \"top\": \"relu1\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc2\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"relu1\",\n",
    "            \"top\": \"fc2\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 256\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu2\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc2\",\n",
    "            \"top\": \"relu2\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc3\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"relu2\",\n",
    "            \"top\": \"fc3\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": embedding_vec_size\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu3\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc3\",\n",
    "            \"top\": \"relu3\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"interaction1\",\n",
    "            \"type\": \"Interaction\",\n",
    "            \"bottom\": [\n",
    "                \"relu3\",\n",
    "                \"sparse_embedding1\"\n",
    "            ],\n",
    "            \"top\": \"interaction1\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc4\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"interaction1\",\n",
    "            \"top\": \"fc4\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 1024\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu4\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc4\",\n",
    "            \"top\": \"relu4\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc5\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"relu4\",\n",
    "            \"top\": \"fc5\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 1024\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu5\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc5\",\n",
    "            \"top\": \"relu5\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc6\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"relu5\",\n",
    "            \"top\": \"fc6\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 512\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu6\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc6\",\n",
    "            \"top\": \"relu6\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc7\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"relu6\",\n",
    "            \"top\": \"fc7\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 256\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"relu7\",\n",
    "            \"type\": \"ReLU\",\n",
    "            \"bottom\": \"fc7\",\n",
    "            \"top\": \"relu7\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"fc8\",\n",
    "            \"type\": \"InnerProduct\",\n",
    "            \"bottom\": \"relu7\",\n",
    "            \"top\": \"fc8\",\n",
    "            \"fc_param\": {\n",
    "                \"num_output\": 1\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"loss\",\n",
    "            \"type\": \"BinaryCrossEntropyLoss\",\n",
    "            \"bottom\": [\n",
    "                \"fc8\",\n",
    "                \"label\"\n",
    "            ],\n",
    "            \"top\": \"loss\"\n",
    "        }\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"optimizer\": optimizer,\n",
    "    \"layers\": layers\n",
    "}\n",
    "with open(config_file_path,'w') as f:\n",
    "    json.dump(config,f,indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14d03h59m04s][HUGECTR][INFO]: Global seed is 619798231\n",
      "[14d03h59m04s][HUGECTR][INFO]: Peer-to-peer access cannot be fully enabled.\n",
      "Device 0: NVIDIA A100-SXM4-40GB\n",
      "[14d03h59m04s][HUGECTR][INFO]: cache_eval_data is not specified using default: 0\n",
      "[14d03h59m04s][HUGECTR][INFO]: num_workers is not specified using default: 1\n",
      "[14d03h59m04s][HUGECTR][INFO]: num of DataReader workers: 1\n",
      "[14d03h59m04s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[14d03h59m04s][HUGECTR][INFO]: num_internal_buffers 1\n",
      "[14d03h59m04s][HUGECTR][INFO]: Vocabulary size: 3090372\n",
      "[14d03h59m04s][HUGECTR][INFO]: max_vocabulary_size_per_gpu_=3090372\n",
      "[14d03h59m04s][HUGECTR][INFO]: All2All Warmup Start\n",
      "[14d03h59m04s][HUGECTR][INFO]: All2All Warmup End\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot0 , slot_size=90397, key_offset=0, value_index_offset=0\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot1 , slot_size=18, key_offset=90397, value_index_offset=90397\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot2 , slot_size=235, key[HUGECTR][INFO] iter: 0; loss: 0.284906; lr: 0.000000\n",
      "_offset=90415, value_index_offset=90415\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot3 , slot_size=18, key_offset=90650, value_index_offset=90650\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot4 , slot_size=239, key_offset=90668, value_index_offset=90668\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot5 , slot_size=19, key_offset=90907, value_index_offset=90907\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot6 , slot_size=236, key_offset=90926, value_index_offset=90926\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot7 , slot_size=18, key_offset=91162, value_index_offset=91162\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot8 , slot_size=235, key_offset=91180, value_index_offset=91180\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot9 , slot_size=18, key_offset=91415, value_index_offset=91415\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot10 , slot_size=229, key_offset=91433, value_index_offset=91433\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot11 , slot_size=18, key_offset=91662, value_index_offset=91662\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot12 , slot_size=224, key_offset=91680, value_index_offset=91680\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot13 , slot_size=18, key_offset=91904, value_index_offset=91904\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot14 , slot_size=225, key_offset=91922, value_index_offset=91922\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot15 , slot_size=18, key_offset=92147, value_index_offset=92147\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot16 , slot_size=219, key_offset=92165, value_index_offset=92165\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot17 , slot_size=17, key_offset=92384, value_index_offset=92384\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot18 , slot_size=213, key_offset=92401, value_index_offset=92401\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot19 , slot_size=17, key_offset=92614, value_index_offset=92614\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot20 , slot_size=199, key_offset=92631, value_index_offset=92631\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot21 , slot_size=26708, key_offset=92830, value_index_offset=92830\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot22 , slot_size=26708, key_offset=119538, value_index_offset=119538\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot23 , slot_size=2232749, key_offset=146246, value_index_offset=146246\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot24 , slot_size=711223, key_offset=2378995, value_index_offset=2378995\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot25 , slot_size=16, key_offset=3090218, value_index_offset=3090218\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot26 , slot_size=61, key_offset=3090234, value_index_offset=3090234\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot27 , slot_size=61, key_offset=3090295, value_index_offset=3090295\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot28 , slot_size=6, key_offset=3090356, value_index_offset=3090356\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot29 , slot_size=7, key_offset=3090362, value_index_offset=3090362\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot30 , slot_size=3, key_offset=3090369, value_index_offset=3090369\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 init embedding done\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot0 , slot_size=90397, key_offset=0, value_index_offset=0\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot1 , slot_size=18, key_offset=90397, value_index_offset=90397\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot2 , slot_size=235, key_offset=90415, value_index_offset=90415\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot3 , slot_size=18, key_offset=90650, value_index_offset=90650\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot4 , slot_size=239, key_offset=90668, value_index_offset=90668\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot5 , slot_size=19, key_offset=90907, value_index_offset=90907\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot6 , slot_size=236, key_offset=90926, value_index_offset=90926\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot7 , slot_size=18, key_offset=91162, value_index_offset=91162\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot8 , slot_size=235, key_offset=91180, value_index_offset=91180\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot9 , slot_size=18, key_offset=91415, value_index_offset=91415\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot10 , slot_size=229, key_offset=91433, value_index_offset=91433\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot11 , slot_size=18, key_offset=91662, value_index_offset=91662\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot12 , slot_size=224, key_offset=91680, value_index_offset=91680\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot13 , slot_size=18, key_offset=91904, value_index_offset=91904\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot14 , slot_size=225, key_offset=91922, value_index_offset=91922\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot15 , slot_size=18, key_offset=92147, value_index_offset=92147\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot16 , slot_size=219, key_offset=92165, value_index_offset=92165\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot17 , slot_size=17, key_offset=92384, value_index_offset=92384\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot18 , slot_size=213, key_offset=92401, value_index_offset=92401\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot19 , slot_size=17, key_offset=92614, value_index_offset=92614\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot20 , slot_size=199, key_offset=92631, value_index_offset=92631\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot21 , slot_size=26708, key_offset=92830, value_index_offset=92830\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot22 , slot_size=26708, key_offset=119538, value_index_offset=119538\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot23 , slot_size=2232749, key_offset=146246, value_index_offset=146246\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot24 , slot_size=711223, key_offset=2378995, value_index_offset=2378995\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot25 , slot_size=16, key_offset=3090218, value_index_offset=3090218\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot26 , slot_size=61, key_offset=3090234, value_index_offset=3090234\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot27 , slot_size=61, key_offset=3090295, value_index_offset=3090295\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot28 , slot_size=6, key_offset=3090356, value_index_offset=3090356\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot29 , slot_size=7, key_offset=3090362, value_index_offset=3090362\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 start to init embedding of slot30 , slot_size=3, key_offset=3090369, value_index_offset=3090369\n",
      "[14d03h59m04s][HUGECTR][INFO]: gpu0 init embedding done\n",
      "[HUGECTR][INFO] iter: 1000; loss: 0.183242; lr: 0.000100\n",
      "[HUGECTR][INFO] iter: 2000; loss: 0.180820; lr: 0.000200\n",
      "[HUGECTR][INFO] iter: 3000; loss: 0.148929; lr: 0.000300\n",
      "[HUGECTR][INFO] iter: 4000; loss: 0.164362; lr: 0.000400\n",
      "[HUGECTR][INFO] iter: 5000; loss: 0.181261; lr: 0.000500\n",
      "[HUGECTR][INFO] iter: 6000; loss: 0.161969; lr: 0.000600\n",
      "[HUGECTR][INFO] iter: 7000; loss: 0.196978; lr: 0.000700\n",
      "[HUGECTR][INFO] iter: 8000; loss: 0.163379; lr: 0.000800\n",
      "[HUGECTR][INFO] iter: 9000; loss: 0.130463; lr: 0.000900\n",
      "[HUGECTR][INFO] iter: 10000; loss: 0.156159; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 10000, [('AUC', 0.6367923021316528)]\n",
      "[14d03h59m41s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[14d03h59m41s][HUGECTR][INFO]: Rank0: Write hash table <key,slot_id,value> pairs to file\n",
      "[14d03h59m41s][HUGECTR][INFO]: Done\n",
      "[14d03h59m41s][HUGECTR][INFO]: Rank0: Write optimzer state to file\n",
      "[14d03h59m41s][HUGECTR][INFO]: Done\n",
      "[14d03h59m41s][HUGECTR][INFO]: Rank0: Write optimzer state to file\n",
      "[14d03h59m41s][HUGECTR][INFO]: Done\n",
      "[HUGECTR][INFO] iter: 11000; loss: 0.140895; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 12000; loss: 0.157411; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 13000; loss: 0.171156; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 14000; loss: 0.165631; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 15000; loss: 0.136090; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 16000; loss: 0.142181; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 17000; loss: 0.162355; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 18000; loss: 0.141721; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 19000; loss: 0.149595; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 20000; loss: 0.154121; lr: 0.001000\n",
      "[HUGECTR][INFO] iter: 20000, [('AUC', 0.6227931976318359)]\n",
      "[14d04h00m18s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[14d04h00m18s][HUGECTR][INFO]: Rank0: Write hash table <key,slot_id,value> pairs to file\n",
      "[14d04h00m19s][HUGECTR][INFO]: Done\n",
      "[14d04h00m19s][HUGECTR][INFO]: Rank0: Write optimzer state to file\n",
      "[14d04h00m19s][HUGECTR][INFO]: Done\n",
      "[14d04h00m19s][HUGECTR][INFO]: Rank0: Write optimzer state to file\n",
      "[14d04h00m19s][HUGECTR][INFO]: Done\n",
      "[HUGECTR][INFO] iter: 21000; loss: 0.148132; lr: 0.000995\n",
      "[HUGECTR][INFO] iter: 22000; loss: 0.165560; lr: 0.000990\n",
      "[HUGECTR][INFO] iter: 23000; loss: 0.144193; lr: 0.000985\n",
      "[HUGECTR][INFO] iter: 24000; loss: 0.148417; lr: 0.000980\n",
      "[HUGECTR][INFO] iter: 25000; loss: 0.133796; lr: 0.000975\n",
      "[HUGECTR][INFO] iter: 26000; loss: 0.182519; lr: 0.000970\n",
      "[HUGECTR][INFO] iter: 27000; loss: 0.145454; lr: 0.000965\n",
      "[HUGECTR][INFO] iter: 28000; loss: 0.144644; lr: 0.000960\n",
      "[HUGECTR][INFO] iter: 29000; loss: 0.152646; lr: 0.000955\n",
      "[HUGECTR][INFO] iter: 30000; loss: 0.173836; lr: 0.000950\n",
      "[HUGECTR][INFO] iter: 30000, [('AUC', 0.6440927982330322)]\n",
      "[14d04h00m56s][HUGECTR][INFO]: Rank0: Dump hash table from GPU0\n",
      "[14d04h00m56s][HUGECTR][INFO]: Rank0: Write hash table <key,slot_id,value> pairs to file\n",
      "[14d04h00m56s][HUGECTR][INFO]: Done\n",
      "[14d04h00m56s][HUGECTR][INFO]: Rank0: Write optimzer state to file\n",
      "[14d04h00m56s][HUGECTR][INFO]: Done\n",
      "[14d04h00m56s][HUGECTR][INFO]: Rank0: Write optimzer state to file\n",
      "[14d04h00m56s][HUGECTR][INFO]: Done\n"
     ]
    }
   ],
   "source": [
    "# Solver related parameters\n",
    "NUM_GPUS = [0]                                               # GPUs used for training\n",
    "json_file = config_file_path                                       # Path to the json config file\n",
    "batchsize = 2048                                                   # Batch size used for training\n",
    "batchsize_eval = 2048                                              # Batch size used during evaluation\n",
    "max_eval_batches = 3768                                            # Iterations required to go through the complete validation set with the set batchsize_eval\n",
    "\n",
    "# Training related parameters\n",
    "num_iter = 30001                                                   # Iterations to train the model for\n",
    "eval_trigger = 10000                                               # Start evaluation after these iterations\n",
    "snapshot_trigger = 10000                                           # Save model checkpoints after these iterations\n",
    "\n",
    "solver_config = solver_parser_helper(\n",
    "                                    seed = 0,\n",
    "                                    batchsize = batchsize,                       # Minibatch size for training\n",
    "                                    batchsize_eval = batchsize_eval,         # Minibatch size for eval \n",
    "                                    max_eval_batches = max_eval_batches,     # Max no. of eval batches on which eval will be done\n",
    "                                    model_file = \"\",                         # Load any pretrained model , if training from scratch, leave empty\n",
    "                                    embedding_files = [],                    # Path to trained embedding table, if training from scratch then leave empty\n",
    "                                    vvgpu = [NUM_GPUS],                      # GPU Indices to be used ofr training\n",
    "                                    use_mixed_precision = False,             # Flag to indicate use of Mixed precision training \n",
    "                                    scaler = 1024,                           # To be set when MixedPrecisiontraining is ON\n",
    "                                    i64_input_key = True,                    # As we are using Parquet from NVTabular, I64 should be true \n",
    "                                    use_algorithm_search = False,            # Enable algo search within the fully connected-layers\n",
    "                                    use_cuda_graph = False,                  # Enable cuda graph for forward and back proppogation\n",
    "                                    repeat_dataset = True                    # Repeat the dataset for training, True for Non Epoch Based Training\n",
    "                                    )\n",
    "\n",
    "lr_sch = get_learning_rate_scheduler(json_file)                    # Get learning rate statistics from optimizers     \n",
    "\n",
    "sess = Session(solver_config, json_file)                           # Initialise a Session Object\n",
    "sess.start_data_reading()                                          # Start Data Reading\n",
    "\n",
    "for i in range(num_iter):                                          # Start training loop\n",
    "    lr = lr_sch.get_next()                                         # Update learning rate parameters                                   \n",
    "    sess.set_learning_rate(lr)                                     # Pass the updated learning rate to the session\n",
    "    sess.train()                                                   # Train on 1 iteration on 1 Minibatch\n",
    "\n",
    "    if (i%1000 == 0):\n",
    "        loss = sess.get_current_loss()                             # Returns the loss value for the current iteration.\n",
    "        print(\"[HUGECTR][INFO] iter: {}; loss: {:.6f}; lr: {:.6f}\".format(i, loss, lr))\n",
    "    if (i%eval_trigger == 0 and i != 0):\n",
    "        sess.check_overflow()                                      # Checks whether any embedding has encountered overflow\n",
    "        sess.copy_weights_for_evaluation()                         # Copies the weights of the dense network from training layers to evaluation layers.\n",
    "        for _ in range(solver_config.max_eval_batches):\n",
    "            sess.eval()                                            # Calculates the evaluation metrics based on one minibatch of evaluation data\n",
    "        metrics = sess.get_eval_metrics()                          # Returns the average evaluation metrics of several minibatches of evaluation data.\n",
    "        print(\"[HUGECTR][INFO] iter: {}, {}\".format(i, metrics))\n",
    "    if (i%snapshot_trigger == 0 and i != 0):\n",
    "        sess.download_params_to_files(weights_output_path , i)     # Saving model"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
